{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5603dace",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 7.2.4 Truncated Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9650bec3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En muchas aplicaciones reales, basta con poder reconstruir las matrices aproximadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a40a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Considere la descomposición espectral de la matriz $D$ basada en la discusión de la sección anterior:\n",
    "\n",
    "$$ D = Q\\Sigma P^{T} = \\sum_{r = 1}^{\\min\\{r,d\\}} \\sigma_{rr}q_{r}p_{r}^{T} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc78d79d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En lugar de descartar únicamente los componentes aditivos para los que $\\sigma_{rr} = 0$, también podríamos descartar aquellos componentes para los que $\\sigma_{rr}$ es muy pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6808c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En otras palabras, mantenemos los valores top-k de σrr en la descomposición (como SVD compacto), excepto que k podría ser menor que el número de valores singulares distintos de cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5d678",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En tal caso, obtenemos una aproximación $D_{k}$ del original matriz $D$, que también se conoce como la aproximación de rango-$k$ de la matriz $D$ de tamaño $n \\times d$:  \n",
    "\n",
    "$$D \\approx D_{k} = \\sum_{r = 1}^{k}\\sigma_{rr}q_{r}p_{r}^{T} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509f84e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that Equation 7.4 for truncated singular value decomposition is the same as that for compact singular value decomposition (cf. Equation 7.2); the only difference is that the value of $k$ is no longer chosen to ensure zero information loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56741e90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consequently, we can express truncated singular value decomposition as a matrix factorization as follows;\n",
    "\n",
    "$$ D \\approx D_{k} = Q_{k}\\Sigma_{k}P_{k}^{T} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1250b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aquí, $ Q_ {k} $ es una matriz $ n \\times k $ con columnas que contienen los vectores singulares de la parte superior-k izquierda, $ \\Sigma_ {k} $ es una matriz diagonal de $ k \\times k $ que contiene la parte superior-k valores singulares, y $ P_ {k} $ es una matriz $ d \\times k $ con columnas que contienen los $k$ vectores singulares superiores derechos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c3924",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "No es difícil ver que la matriz $D_{k}$ tiene un rango de $k$ y, por lo tanto, se considera una aproximación de rango bajo de $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448edd80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Almost all forms of matrix factorization, including singular value decomposition, are low-rank approximations of the original matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b4df0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Truncated singular value decomposition can retain a surprisingly large level of accuracy using values of $k$ that are much smaller than $\\min{n, d}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91aa1dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is because only a very small proportion of the singular values are large in real-world matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5072599d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In such cases, $D_{k}$ becomes an excellent approximation of D by retaining the few singular vectors that are large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb5f68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A useful property of truncated singular value decomposition is that it is also possible to create a lower dimensional representation of the data by changing the basis to $P_{k}$, so that each $d$-dimensional data point is now represented in only k dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372b194",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In other words, we change the axes so that the basis vectors correspond to the columns of $P_{k}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989b17f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This transformation is achieved by post-multiplying the data matrix $D$ with $P_{k}$ to obtain the $n \\times k$ matrix $U_{k}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08192bbc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By post-multiplying Equation 7.5 with $P_{k}$ and using $P^{T}_{k}P_{k} = I_{k}$, we obtain the following:\n",
    "\n",
    "$$ U_{k} = DP_{k} = Q_{k}\\Sigma_{k} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5eb5d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Each row of $U_{k}$ contains a reduced $k$-dimensional representation of the corresponding row in $D$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f474b16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Therefore, we can obtain a reduced representation of the data either by post-multiplying the data matrix with the matrix containing the dominant right singular vectors (i.e., using $DP_{k}$), or we can simply scale the dominant left singular vectors with the singular values (i.e., using $Q_{k}\\Sigma_{k}$). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94f660d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Both these types of methods are used in real applications, depending on whether n or d is larger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b38838",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The reduction in dimensionality can be very significant in some domains such as images and text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9f38e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Image data are often represented by matrices of numbers corresponding to pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953ef3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, an image corresponding to an 807 × 611 matrix of numbers is illustrated in Figure 7.1(a). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b54e762",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Only the first 75 singular values are represented in Figure 7.1(b). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09acd908",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The remaining 611 − 75 = 536 singular values are not shown because they are very small. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7a396",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = ''>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3cf76",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The rapid decay in singular values is quite evident in the figure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18671ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is this rapid decay that enables effective truncation without loss of accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371eef6f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the text domain, each document is represented as a row in a matrix with as many dimensions as the number of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8cfc08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The value of each entry is the frequency of the word in the corresponding document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83737f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that this matrix is sparse, which is a standard use-case for SVD. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cca92d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The word-frequency matrix D might have n = 106 and d = 105. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2622026",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In such cases, truncated SVD might often yield excellent approximations of the matrix by using k ≈ 400. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cccb22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This represents a drastic level of reduction in the dimensionality of representation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a56e52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The use of SVD in text is also referred to as latent semantic analysis because of its ability to discover latent (hidden) topics represented by the rank-1 matrices of the spectral decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654aa48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14404e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d68919",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37be2f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbcc2d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503bb4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028bd342",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65e180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4351cd5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caac2d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "rise": {
   "enable_chalkboard": true,
   "theme": "sky",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
