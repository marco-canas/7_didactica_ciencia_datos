{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "aprendizaje supervisado se usa siempre que:\n",
    "* queremos predecir un resultado determinado a partir de una entrada determinada, y \n",
    "* tenemos ejemplos de pares de entrada/salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Construimos un **modelo de aprendizaje automático** a partir de estos pares de entrada / salida, que componen nuestro **conjunto de entrenamiento**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nuestro objetivo es realizar predicciones precisas para datos nuevos y nunca antes vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clasificación y regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hay dos tipos principales de **problemas de aprendizaje automático supervisados**, denominados   \n",
    "* clasificación y   \n",
    "* regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En la clasificación:\n",
    "* el objetivo es predecir una etiqueta de clase, \n",
    "* una elección de una lista predefinida de posibilidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejemplo:\n",
    "clasificar florez de iris en una de las tres posibles especies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La clasificación a veces se divide en:  \n",
    "* clasificación binaria,  \n",
    "* clasificación multiclase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ejemplo\n",
    "La clasificación de los correos electrónicos como spam o no spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En la clasificación binaria: \n",
    "* la **clase positiva**  \n",
    "* **clase negativa**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* positivo **no** representa tener beneficio o valor, \n",
    "* sino cuál es el objeto del estudio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuál de las dos clases se llama positivo es a menudo un asunto subjetivo y específico del dominio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El ejemplo de las florez de iris, por otro lado, es un ejemplo de un problema de clasificación multiclase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Otro ejemplo es predecir en qué idioma está un sitio web a partir del texto del sitio web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las clases aquí serían una lista predefinida de posibles idiomas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objetivo de las tareas de regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para las tareas de regresión, el objetivo es predecir \n",
    "* un número continuo o \n",
    "* un *número de punto flotante* en términos de programación \n",
    "* o un *número real* en términos matemáticos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* predecir los ingresos anuales de una persona a partir de su educación, su edad y el lugar donde vive es un ejemplo de una tarea de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Al predecir ingresos, el valor predicho es una cantidad y puede ser cualquier número en un rango dado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Otro ejemplo de una tarea de regresión es predecir el rendimiento de una granja de maíz dados atributos como rendimientos anteriores, clima y número de empleados que trabajan en la granja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El rendimiento nuevamente puede ser un número arbitrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Criterio de distinción entre tarea de regresión y tarea de clasificación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una forma fácil de distinguir entre tareas de clasificación y regresión es preguntarse si existe algún tipo de continuidad en el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si hay continuidad entre los posibles resultados, entonces el problema es un problema de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " Piense en predecir los ingresos anuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hay una clara continuidad en la salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* ganar $40.000$ o $40.001$ al año **no** supone una diferencia tangible; \n",
    "* si nuestro algoritmo predice $39.999$ o $40.001$ cuando debería haber predicho $40.000$, no nos importa mucho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por el contrario, para la tarea de reconocer el idioma de un sitio web (que es un problema de clasificación), no hay cuestión de grado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Un sitio web está en un idioma o en otro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* No hay continuidad entre los idiomas  \n",
    "* no hay idioma que esté entre el inglés y el francés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generalization, Overfitting, and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generalización, sobreajuste y desajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En el aprendizaje supervisado:\n",
    "* construimos un modelo a partir de los datos de entrenamiento y luego \n",
    "* hacemos predicciones precisas sobre datos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si un modelo es capaz de hacer predicciones precisas sobre datos invisibles, decimos que puede generalizar desde el conjunto de entrenamiento al conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Queremos construir un modelo que pueda generalizar con la mayor precisión posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por lo general, construimos un modelo de tal manera que pueda hacer predicciones precisas sobre el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si los conjuntos de entrenamiento y prueba tienen suficiente en común, esperamos que el modelo también sea preciso en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por ejemplo, si nos permitimos construir modelos muy complejos, siempre podemos ser tan precisos como queramos en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Supongamos que un científico de datos novato quiere predecir si un cliente comprará un barco, dados los registros de compradores de barcos anteriores y clientes que sabemos que no están interesados en comprar un barco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "|Age|Number of cars owned|Owns house|Number of children|Marital status|Owns a dog|Bought a boat|   \n",
    "|---|--------------------|----------|------------------|--------------|-----------|-------------|  \n",
    "|66|1|yes|2|widowed|no|yes|  \n",
    "|52|2|yes|3|married|no|yes|  \n",
    "|22|0|no|0|married|yes|no|  \n",
    "|25| 1| no| 1| single| no| no|  \n",
    "|44| 0| no| 2| divorced| yes| no|  \n",
    "|39| 1| yes| 2| married| yes| no|  \n",
    "|26| 1| no| 2| single| no| no|  \n",
    "|40| 3| yes| 1| married| yes| no|  \n",
    "|53| 2| yes| 2| divorced| no| yes|  \n",
    "|64| 2| yes| 3| divorced| no| no|  \n",
    "|58| 2| yes| 2| married| yes| yes|  \n",
    "|33| 1| no| 1| single| no| no| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nuestro científico de datos novato propone la siguiente regla: \n",
    "* \"Si el cliente es mayor de 45 años y tiene menos de 3 hijos o no está divorciado, entonces \n",
    "  quiere comprar un barco\".   \n",
    "  Esta regla enunciada de manera implicativa, permite la construcción de un modelo o función que prediga si un cliente comprará o no un barco. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "nuestro científico de datos dice: \"¡Es 100% precisa!\"\n",
    "* Y de hecho, en los datos que están en la tabla, la regla es perfectamente precisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hay muchas reglas posibles que se nos ocurren y que explican perfectamente si alguien en este conjunto de datos quiere comprar un barco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ninguna edad aparece dos veces en los datos, por lo que podríamos decir que\n",
    "* las personas de 66, 52, 53 o 58 años quieren comprar un barco, mientras que el resto no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si bien podemos crear muchas reglas que funcionen bien con estos datos, recuerde que no estamos interesados en hacer predicciones para este conjunto de datos; ya conocemos las respuestas para estos clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Queremos saber si es probable que nuevos clientes compren un barco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por lo tanto, queremos encontrar una regla que funcione bien para los nuevos clientes, y lograr una precisión del 100 por ciento \n",
    "* y este conjunto de entrenamiento **no** nos ayuda en eso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es posible que **no** podamos confiar en que la regla funcione muy bien en nuevos clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Parece demasiado compleja y \n",
    "* está respaldado por muy pocos datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por ejemplo, la parte de la regla \"o no está divorciado\" depende de un solo cliente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La única medida de si un algoritmo funcionará bien con nuevos datos es la evaluación en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "intuitivamente esperamos que los modelos simples se generalicen mejor a los nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si la regla fuera “Las personas mayores de 50 años quieren comprar un bote”, y esto explicaría el comportamiento de todos los clientes, confiaríamos más en ella que en la regla que involucra a los hijos y el estado civil además de la edad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por eso, siempre queremos encontrar el modelo más simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Construir un modelo que es demasiado complejo para la cantidad de información que tenemos, como lo hizo nuestro científico de datos novato, se llama sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El sobreajuste se produce cuando ajusta un modelo demasiado de cerca a las particularidades del conjunto de entrenamiento y obtiene un modelo que funciona bien en el conjunto de entrenamiento pero no puede generalizar a nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por otro lado, si su modelo es demasiado simple, digamos, \n",
    "* \"Todos los propietarios de una casa compran un bote\",  \n",
    "\n",
    "es posible que no pueda capturar todos los aspectos y la variabilidad de los datos, y su modelo funcionará mal incluso en el set de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La elección de un modelo demasiado simple se llama desajuste (underfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuanto más complejo permitamos que nuestro modelo sea, mejor seremos capaces de predecir los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, si nuestro modelo se vuelve demasiado complejo, comenzamos a enfocarnos demasiado en cada punto de datos individual en nuestro conjunto de entrenamiento, y el modelo no se generalizará bien a nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hay un punto óptimo en el medio que producirá el mejor rendimiento de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este es el modelo que queremos encontrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La compensación entre sobreajuste (overfitting) y desajuste (underfitting) se ilustra en la Figura 2-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "Image('figure_2_1.JPG',width=600,height=300) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relación de la complejidad del modelo con el tamaño del conjunto de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La complejidad del modelo está íntimamente ligada a la variación de las entradas contenidas en tu conjunto de datos de entrenamiento: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "cuanto mayor sea la variedad de puntos de datos que contiene tu conjunto de datos, más complejo es el modelo que puedes usar sin sobreajustar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La recopilación de más puntos de datos producirá más variedad, por lo que los conjuntos de datos más grandes permiten construir modelos más complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, simplemente duplicar los mismos puntos de datos o recopilar datos muy similares no ayudará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si viéramos 10.000 filas más de datos de clientes y todas cumplieran la regla \"Si el cliente es mayor de 45 años y tiene menos de 3 hijos o no está divorciado, entonces quiere comprar un bote ”, sería mucho más probable que creyéramos que esta es una buena regla que cuando se desarrolló utilizando solo las 12 filas de la Tabla anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tener más datos y construir modelos apropiadamente más complejos a menudo puede hacer maravillas para las tareas de aprendizaje supervisado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nos centraremos en trabajar con conjuntos de datos de tamaños fijos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En el mundo real, a menudo tiene la capacidad de decidir cuántos datos recopilar, lo que podría ser más beneficioso que ajustar y reajustar su modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algoritmos de aprendizaje automático supervisados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Revisaremos los algoritmos de aprendizaje automático más populares y explicaremos cómo aprenden de los datos y cómo hacen predicciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* ¿cómo se desarrolla el concepto de **complejidad del modelo**?\n",
    "* descripción general de cómo cada algoritmo construye un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Examinaremos:\n",
    "* las fortalezas y debilidades de cada algoritmo y \n",
    "* a qué tipo de datos se pueden aplicar mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "También explicaremos el significado de los **parámetros** y opciones más importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Muchos algoritmos tienen:\n",
    "* una variante de clasificación y\n",
    "* una variante de regresión,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algunos conjuntos de datos de muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Algunos de los conjuntos de datos serán pequeños y artificiales, diseñados para resaltar aspectos particulares de los algoritmos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Un ejemplo de un conjunto de datos de clasificación sintético de dos clases es el conjunto de datos de `make_forge`, que tiene dos características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El siguiente código crea un diagrama de dispersión que visualiza todos los puntos de datos en este conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La gráfica tiene la primera característica en el eje `x` y la segunda característica en el \"eje `y`\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como siempre ocurre en los gráficos de dispersión, cada punto de datos se representa como un punto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El color y la forma del punto indican su clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mglearn \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:86: FutureWarning: Function make_blobs is deprecated; Please import make_blobs directly from scikit-learn\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# generate dataset\n",
    "X, y = mglearn.datasets.make_forge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Second feature')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot dataset\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.legend([\"Class 0\", \"Class 1\"], loc = 1) \n",
    "plt.xlabel(\"First feature\", color = 'w') \n",
    "plt.ylabel(\"Second feature\", color = 'w') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X.shape \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como puede ver en `X.shape`, este conjunto de datos consta de 26 puntos de datos, con 2 características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para ilustrar los algoritmos de regresión, usaremos el conjunto de datos sintético \"`wave`\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El conjunto de datos de ondas tiene una característica de entrada única y una variable objetivo continua (o respuesta) que queremos modelar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El gráfico creado aquí (Figura 2-3) muestra la característica única en el `eje x` y el objetivo de regresión (la salida) en el` eje y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.make_wave(n_samples = 50)  \n",
    "plt.plot(X, y, 'o')\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Estamos utilizando estos conjuntos de datos muy simples y de baja dimensión porque podemos visualizarlos fácilmente: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "una página impresa tiene dos dimensiones, por lo que los datos con más de dos características son difíciles de mostrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cualquier intuición derivada de conjuntos de datos con pocas características (también llamados conjuntos de datos de baja dimensión) podría no ser válida en conjuntos de datos con muchas características (conjuntos de datos de alta dimensión)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Siempre que tenga esto en cuenta, inspeccionar algoritmos en conjuntos de datos de baja dimensión puede ser muy instructivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Complementaremos estos pequeños conjuntos de datos sintéticos con dos conjuntos de datos del mundo real que se incluyen en `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Uno es el conjunto de datos de Wisconsin Breast Cancer (cáncer, para abreviar), que registra las mediciones clínicas de los tumores de cáncer de mama."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cada tumor se etiqueta como   \n",
    "* \"benigno\" (para tumores inofensivos) o\n",
    "* \"maligno\" (para tumores cancerosos), \n",
    "\n",
    "y la tarea es aprender a predecir si un tumor es maligno en función de las mediciones del tejido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Los datos se pueden cargar usando la función `load_breast_cancer()` de `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Los conjuntos de datos que se incluyen en `scikit-learn` generalmente se almacenan como objetos `Bunch`, que contienen información sobre el conjunto de datos, así como los datos reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Todo lo que necesita saber sobre los objetos `Bunch` es que se comportan como diccionarios, con el beneficio adicional de que puede acceder a los valores usando un punto (como en `bunch.key` en lugar de `bunch['key'] `)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El conjunto de datos consta de 569 puntos de datos, con 30 características cada uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cancer.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.sum(cancer.target)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De estos 569 puntos de datos, 212 están etiquetados como malignos y 357 como benignos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "dic = {k: v for k, v in zip(cancer.target_names, np.bincount(cancer.target))}\n",
    "dic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(dic, index = [0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "list(zip([1,2],['a','b'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cancer.target_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.bincount(cancer.target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[numpy.bincount](https://numpy.org/doc/stable/reference/generated/numpy.bincount.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para obtener una descripción del significado semántico de cada característica, podemos echar un vistazo al atributo `feature_names`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Feature names:\\n{}\".format(cancer.feature_names)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Puede obtener más información sobre los datos leyendo \"cancer.DESCR\" si está interesado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "También usaremos un conjunto de datos de regresión del mundo real, el conjunto de datos de Boston Housing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La tarea asociada con este conjunto de datos es predecir el valor medio de las viviendas en varios vecindarios de Boston en la década de 1970, utilizando información como la tasa de criminalidad, la proximidad al río Charles, la accesibilidad a las carreteras, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El conjunto de datos contiene 506 puntos de datos, descritos por 13 características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(\"Data shape: {}\".format(boston.data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nuevamente, puede obtener más información sobre el conjunto de datos leyendo el atributo `DESCR` de boston."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para nuestros propósitos aquí, en realidad expandiremos este conjunto de datos no solo considerando estas 13 medidas como características de entrada, sino también observando todos los productos (también llamados interacciones) entre características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En otras palabras, no solo consideraremos la tasa de delincuencia y la accesibilidad a las carreteras como características, sino también el producto de la tasa de delincuencia y la accesibilidad a las carreteras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La inclusión de características derivadas como estas se denomina ingeniería de características, que analizaremos con más detalle en el Capítulo 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este conjunto de datos derivado se puede cargar usando la función `load _extended_ boston`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las 104 características resultantes son las 13 características originales junto con las 91 combinaciones posibles de dos características dentro de esas 13 (con reemplazo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Usaremos estos conjuntos de datos para explicar e ilustrar las propiedades de los diferentes algoritmos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El algoritmo `k-NN` es posiblemente el algoritmo de aprendizaje automático más simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La construcción del modelo consiste solo en almacenar el conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para hacer una predicción de un nuevo punto de datos, el algoritmo busca los puntos de datos más cercanos en el conjunto de datos de entrenamiento: sus \"vecinos más cercanos\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### k - Neighbors classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Clasificación de k - vecinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En su versión más simple, el algoritmo `k-NN` solo considera exactamente un vecino más cercano, que es el punto de datos de entrenamiento más cercano al punto para el que queremos hacer una predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Entonces, la predicción es simplemente la salida conocida para este punto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mglearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aquí, agregamos tres nuevos puntos de datos, que se muestran como estrellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para cada uno de ellos, marcamos el punto más cercano en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La predicción del algoritmo de un vecino más cercano es la etiqueta de ese punto (mostrado por el color de la estrella)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En lugar de considerar solo al vecino más cercano, también podemos considerar un número arbitrario, $k$, de vecinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aquí es de donde proviene el nombre del algoritmo de los $k$ vecinos más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando consideramos a más de un vecino, usamos la **votación** para asignar una etiqueta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto significa que para cada punto de prueba, contamos cuántos vecinos pertenecen a la clase 0 y cuántos vecinos pertenecen a la clase 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Luego asignamos la clase que es más frecuente: en otras palabras, la clase mayoritaria entre los $k$ vecinos más cercanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mglearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=3)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nuevamente, la predicción se muestra como el color de la estrella. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Puede ver que la predicción para el nuevo punto de datos en la parte superior izquierda no es la misma que la predicción cuando usamos solo un vecino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si bien esta ilustración es para un problema de clasificación binaria, este método se puede aplicar a conjuntos de datos con cualquier número de clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para más clases, contamos cuántos vecinos pertenecen a cada clase y nuevamente predecimos la clase más común."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora veamos cómo podemos aplicar el algoritmo de k vecinos más cercanos usando scikitlearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Primero, dividimos nuestros datos en un conjunto de entrenamiento y un conjunto de prueba para que podamos evaluar el desempeño de la generalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A continuación, importamos y creamos una instancia de la clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aquí es cuando podemos establecer parámetros, como el número de vecinos a utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aquí, lo configuramos en 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora, ajustamos el clasificador usando el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para `KNeighborsClassifier` esto significa almacenar el conjunto de datos, para que podamos calcular los vecinos durante la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para hacer predicciones sobre los datos de prueba, llamamos al método de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para cada punto de datos en el conjunto de prueba, esto calcula sus vecinos más cercanos en el conjunto de entrenamiento y encuentra la clase más común entre estos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para evaluar qué tan bien se generaliza nuestro modelo, podemos llamar al método de puntuación (`score()`) con los datos de la prueba junto con las etiquetas de la prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vemos que nuestro modelo tiene una precisión del 86%, lo que significa que el modelo predijo la clase correctamente para el 86% de las muestras en el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Analyzing `KNeighborsClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para conjuntos de datos bidimensionales, también podemos ilustrar la predicción para todos los posibles puntos de prueba en el plano `xy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Coloreamos el plano de acuerdo con la clase que se le asignaría a un punto en esta región."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto nos permite ver el límite de decisión, que es la división entre dónde el algoritmo asigna la clase 0 y dónde asigna la clase 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El siguiente código produce las visualizaciones de los límites de decisión para uno, tres y nueve vecinos que se muestran en la Figura 2-6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mglearn  \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = mglearn.datasets.make_forge() \n",
    "X_train,y_train,X_test,y_test = train_test_split(X,y,random_state=0) \n",
    "clf = KNeighborsClassifier(n_neighbors = 3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize = (10, 3))\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    clf = KNeighborsClassifier(n_neighbors = n_neighbors).fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(clf, X, fill = True, eps = 0.5, ax = ax, alpha = .4)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax = ax)\n",
    "    ax.set_title(\"{} neighbor(s)\".format(n_neighbors))\n",
    "    ax.set_xlabel(\"feature 0\")\n",
    "    ax.set_ylabel(\"feature 1\")\n",
    "axes[0].legend(loc=3)\n",
    "plt.savefig('uno_tres_nueve_vecinos.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La figura anterior presenta los límites de decisión creados por el modelo de vecinos más cercanos para diferentes valores de `n_neighbors`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como puede ver a la izquierda en la figura, el uso de un solo vecino da como resultado un límite de decisión que sigue de cerca los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tener en cuenta cada vez más vecinos conduce a un límite de decisión más suave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Un límite más suave corresponde a un modelo más simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En otras palabras, usar pocos vecinos corresponde a una alta complejidad del modelo (como se muestra en el lado derecho de la Figura 2-1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "y usar muchos vecinos corresponde a una baja complejidad del modelo (como se muestra en el lado izquierdo de la Figura 2-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si considera el caso extremo en el que el número de vecinos es el número de todos los puntos de datos en el conjunto de entrenamiento, cada punto de prueba tendría exactamente los mismos vecinos (todos los puntos de entrenamiento) y todas las predicciones serían iguales: la clase que es más frecuente en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Investiguemos si podemos confirmar la conexión entre la complejidad del modelo y la generalización que discutimos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Haremos esto en el conjunto de datos de cáncer de mama del mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comenzamos dividiendo el conjunto de datos en un conjunto de entrenamiento y uno de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Luego, evaluamos el rendimiento del equipo de entrenamiento y prueba con diferentes números de vecinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Los resultados se muestran en la siguiente figura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 11)\n",
    "for n_neighbors in neighbors_settings:\n",
    "# build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "# record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "# record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El gráfico muestra la precisión del conjunto de entrenamiento y prueba en el eje $y$ frente a la configuración de \"`n_neighbors`\" en el eje $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si bien los gráficos del mundo real rara vez son muy suaves, aún podemos reconocer algunas de las características del sobreajuste y el desajuste "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "(tenga en cuenta que debido a que considerar menos vecinos corresponde a un modelo más complejo, el gráfico se invierte horizontalmente en relación con la ilustración de la Figura 2-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Teniendo en cuenta un solo vecino más cercano, la predicción en el conjunto de entrenamiento es perfecta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pero cuando se consideran más vecinos, el modelo se vuelve más simple y la precisión del entrenamiento disminuye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La precisión del conjunto de testeo prueba al usar un solo vecino es menor que cuando usa más vecinos, lo que indica que usar un único vecino más cercano conduce a un modelo que es demasiado complejo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por otro lado, al considerar 10 vecinos, el modelo es demasiado simple y el rendimiento es aún peor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El mejor rendimiento se encuentra en algún punto intermedio, utilizando alrededor de seis vecinos. Aún así, es bueno tener en cuenta la escala del gráfico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El peor rendimiento es de alrededor del 88% de precisión, que aún podría ser aceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k-neighbors regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## regresión de k-vecinos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "También hay una variante de regresión del algoritmo de los k vecinos más cercanos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* comencemos por usar el único vecino más cercano,\n",
    "* usemos el conjunto de datos `wave`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Agregamos tres puntos de datos de prueba como estrellas verdes en el eje x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* La predicción que utiliza un solo vecino es solo el valor objetivo del vecino más cercano. \n",
    "* Estos se muestran como estrellas azules en la Figura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nuevamente, podemos usar más que el único vecino más cercano para la regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando se utilizan varios vecinos más cercanos, la predicción es el promedio, o la media, de los vecinos relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* El algoritmo de k vecinos más cercanos para la regresión se implementa en la clase \n",
    "  `KNeighborsRegressor` en scikit-learn. \n",
    "* Se usa de manera similar a `KNeighborsClassifier`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mglearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "# split the wave dataset into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# instantiate the model and set the number of neighbors to consider to 3\n",
    "reg = KNeighborsRegressor(n_neighbors=3)\n",
    "# fit the model using the training data and training targets\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Ahora podemos hacer predicciones en el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Test set predictions:\\n{}\".format(reg.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also evaluate the model using the score method, which for regressors returns the R2 score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The R2 score, also known as the coefficient of determination, is a measure of goodness of a prediction for a regression model, and yields a score between 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A value of 1 corresponds to a perfect prediction, and a value of 0 corresponds to a constant model that just predicts the mean of the training set responses, y_train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Test set R^2: {:.2f}\".format(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here, the score is 0.83, which indicates a relatively good model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analyzing KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For our one-dimensional dataset, we can see what the predictions look like for all possible feature values (Figure 2-10). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To do this, we create a test dataset consisting of many points on the line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "# create 1,000 data points, evenly spaced between -3 and 3\n",
    "line = np.linspace(-3, 3, 1000).reshape(-1, 1)\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # make predictions using 1, 3, or 9 neighbors\n",
    "    reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    reg.fit(X_train, y_train)\n",
    "    ax.plot(line, reg.predict(line))\n",
    "    ax.plot(X_train, y_train, '^', c=mglearn.cm2(0), markersize=8)\n",
    "    ax.plot(X_test, y_test, 'v', c=mglearn.cm2(1), markersize=8)\n",
    "    ax.set_title(\n",
    "    \"{} neighbor(s)\\n train score: {:.2f} test score: {:.2f}\".format(\n",
    "    n_neighbors, reg.score(X_train, y_train),\n",
    "    reg.score(X_test, y_test)))\n",
    "    ax.set_xlabel(\"Feature\")\n",
    "    ax.set_ylabel(\"Target\")\n",
    "axes[0].legend([\"Model predictions\", \"Training data/target\",\n",
    "\"Test data/target\"], loc=\"best\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Figure 2-10. Comparing predictions made by nearest neighbors regression for different\n",
    "values of n_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we can see from the plot, using only a single neighbor, each point in the training set has an obvious influence on the predictions, and the predicted values go through all of the data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This leads to a very unsteady prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Considering more neighbors leads to smoother predictions, but these do not fit the training data as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Strengths, weaknesses, and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fortalezas, debilidades y parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En principio, hay dos parámetros importantes para el `KNeighborsClassifier`: el número de vecinos y cómo mide la distancia entre puntos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En la práctica, el uso de una pequeña cantidad de vecinos, como tres o cinco, suele funcionar bien, pero sin duda debería ajustar este parámetro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La elección de la medida de distancia correcta está un poco más allá del alcance de este libro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De forma predeterminada, se utiliza la distancia euclidiana, que funciona bien en muchos entornos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Uno de los puntos fuertes de k-NN es que el modelo es muy fácil de entender y, a menudo, ofrece un rendimiento razonable sin muchos ajustes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El uso de este algoritmo es un buen método de referencia para probar antes de considerar técnicas más avanzadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La construcción del modelo de vecinos más cercanos suele ser muy rápida, pero cuando su conjunto de entrenamiento es muy grande (ya sea en número de características o en número de muestras) la predicción puede ser lenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Al utilizar el algoritmo k-NN, es importante preprocesar sus datos (consulte el Capítulo 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este enfoque a menudo no funciona bien en conjuntos de datos con muchas características (cientos o más), y lo hace particularmente mal con conjuntos de datos donde la mayoría de las características son 0 la mayor parte del tiempo (los denominados conjuntos de datos dispersos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Entonces, aunque el algoritmo de k-vecinos más cercano es fácil de entender, no se usa a menudo en la práctica, debido a que la predicción es lenta y su incapacidad para manejar muchas características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El método que discutimos a continuación no tiene ninguno de estos inconvenientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Los modelos lineales son una clase de modelos que se utilizan ampliamente en la práctica y se han estudiado ampliamente en las últimas décadas, con raíces que se remontan a más de cien años."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Linear models make a prediction using a linear function of the input features, which we will explain shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear models for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modelos lineales para regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para la regresión, la fórmula de predicción general para un modelo lineal tiene el siguiente aspecto:\n",
    "\n",
    "$$ \\hat{y} = w[0] * x[0] + w[1] * x[1] + \\cdots + w[p] * x[p] + b $$\n",
    "\n",
    "Aquí, $x[0]$ a $x[p]$ denota las características (en este ejemplo, el número de características es $p+1$) de un solo punto de datos, $w$ y $b$ son parámetros del modelo que se aprenden y $\\hat{y}$ es la predicción que hace el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For a dataset with a single feature, this is:\n",
    " \n",
    "$$ \\hat{y} = w[0] * x[0] + b $$ \n",
    "\n",
    "which you might remember from high school mathematics as the equation for a line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here, $w[0]$ is the slope and b is the y-axis offset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For more features, $w$ contains the slopes along each feature axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternatively, you can think of the predicted response as being a weighted sum of the input features, with weights (which can be negative) given by the entries of $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Trying to learn the parameters w[0] and b on our one-dimensional wave dataset might lead to the following line (see Figure 2-11):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_linear_regression_wave()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Figure 2-11. Predictions of a linear model on the wave dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We added a coordinate cross into the plot to make it easier to understand the line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Looking at $w[0]$ we see that the slope should be around 0.4, which we can confirm visually in the plot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The intercept is where the prediction line should cross the y-axis:\n",
    "this is slightly below zero, which you can also confirm in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Linear models for regression can be characterized as regression models for which the prediction is a line for a single feature, a plane when using two features, or a hyperplane in higher dimensions (that is, when using more features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you compare the predictions made by the straight line with those made by the `KNeighborsRegressor` in Figure 2-10, using a straight line to make predictions seems very restrictive. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It looks like all the fine details of the data are lost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In a sense, this is\n",
    "true. It is a strong (and somewhat unrealistic) assumption that our target y is a linear combination of the features. But looking at one-dimensional data gives a somewhat\n",
    "skewed perspective. For datasets with many features, linear models can be very powerful.\n",
    "In particular, if you have more features than training data points, any target y\n",
    "can be perfectly modeled (on the training set) as a linear function.6\n",
    "There are many different linear models for regression. The difference between these\n",
    "models lies in how the model parameters w and b are learned from the training data,\n",
    "and how model complexity can be controlled. We will now take a look at the most\n",
    "popular linear models for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Linear regression (aka ordinary least squares)\n",
    "Linear regression, or ordinary least squares (OLS), is the simplest and most classic linear\n",
    "method for regression. Linear regression finds the parameters w and b that minimize\n",
    "the mean squared error between predictions and the true regression targets, y,\n",
    "on the training set. The mean squared error is the sum of the squared differences\n",
    "between the predictions and the true values. Linear regression has no parameters,\n",
    "which is a benefit, but it also has no way to control model complexity.\n",
    "Here is the code that produces the model you can see in Figure 2-11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The “slope” parameters (w), also called weights or coefficients, are stored in the coef_\n",
    "attribute, while the offset or intercept (b) is stored in the intercept_ attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('dark_background')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "rise": {
   "enable_chalkboard": true,
   "theme": "sky",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
