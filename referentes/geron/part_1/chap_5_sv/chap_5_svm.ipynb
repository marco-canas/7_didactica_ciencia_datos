{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b60c0a4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/introducci-n-al-Machine-Learning/blob/main/classes/class_1/class_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f50600",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 5. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541097ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una máquina de soporte vectorial (SVM) es un modelo de aprendizaje automático potente y versátil, capaz de realizar clasificación lineal o no lineal, regresión e incluso detección de valores atípicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4a4c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es uno de los modelos más populares en Machine Learning, y cualquier persona interesada en Machine Learning debería tenerlo en su caja de herramientas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf76a4bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las SVM son particularmente adecuadas para la clasificación de conjuntos de datos complejos de tamaño pequeño o mediano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64899e27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este capítulo explicará los conceptos básicos de las SVM, cómo usarlas y cómo funcionan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885bb1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792f3f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La idea fundamental detrás de las SVM se explica mejor con algunas imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f0c382",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La Figura 5-1 muestra parte del conjunto de datos del iris que se presentó al final del Capítulo 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c943614",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las dos clases se pueden separar fácilmente con una línea recta (son linealmente separables). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1babb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El gráfico de la izquierda muestra los límites de decisión de tres posibles clasificadores lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c15bbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_1/chap_5_sv/figure_5_1.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d293491d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El modelo cuyo límite de decisión está representado por la línea discontinua es tan malo que ni siquiera separa las clases correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa64669f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Los otros dos modelos funcionan perfectamente en este conjunto de entrenamiento, pero sus límites de decisión se acercan tanto a las instancias que estos modelos probablemente no funcionarán tan bien en nuevas instancias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486e518",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por el contrario, la línea continua en el gráfico de la derecha representa el límite de decisión de un clasificador SVM; esta línea no solo separa las dos clases, sino que también se mantiene lo más alejada posible de las instancias de entrenamiento más cercanas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785325a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Puede pensar en un clasificador SVM como si se ajustara a la calle más ancha posible (representada por las líneas discontinuas paralelas) entre las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267241c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto se llama **clasificación de gran margen**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b83c04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tenga en cuenta que agregar más instancias de capacitación \"fuera de la calle\" no afectará en absoluto el límite de decisión: está completamente determinado (o \"respaldado\") por las instancias ubicadas en el borde de la calle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3968da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Estos casos se denominan vectores de soporte (están encerrados en un círculo en la figura 5-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc272dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_1/chap_5_sv/figure_5_2.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4f8cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ADVERTENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a583d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las SVM son sensibles a las escalas de características, como puede ver en la Figura 5-2: en el gráfico de la izquierda, la escala vertical es mucho más grande que la escala horizontal, por lo que la calle más ancha posible está cerca de la horizontal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc18d4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Después de escalar características (p. ej., usando StandardScaler de Scikit-Learn), el límite de decisión en el gráfico de la derecha se ve mucho mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e76986",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Soft Margin Classification\n",
    "Clasificación de margen blando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3916dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si imponemos estrictamente que todas las instancias deben estar fuera de la calle y del lado derecho, esto se denomina *clasificación de margen duro*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7324f902",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hay dos problemas principales con la clasificación de margen duro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216aa7cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Primero, solo funciona si los datos son linealmente separables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce511324",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En segundo lugar, es sensible a los valores atípicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b73e35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La Figura 5-3 muestra el conjunto de datos del iris con solo un valor atípico adicional: a la izquierda, es imposible encontrar un margen duro; a la derecha, el límite de decisión termina siendo muy diferente del que vimos en la Figura 5-1 sin el valor atípico, y probablemente tampoco se generalice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4146fdd0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_1/chap_5_sv/figure_5_3.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d98cb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para evitar estos problemas, utilice un modelo más flexible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efabdde",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El objetivo es encontrar un buen equilibrio entre mantener la calle lo más grande posible y limitar las violaciones de los márgenes (es decir, instancias que terminan en el medio de la calle o incluso en el lado equivocado)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446fb20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto se llama *clasificación de margen suave*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8e352",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Al crear un modelo SVM con Scikit-Learn, podemos especificar una serie de hiperparámetros. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a46e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "C es uno de esos hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d89b3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si lo establecemos en un valor bajo, terminamos con el modelo a la izquierda de la Figura 5-4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42824d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Con un valor alto, obtenemos el modelo de la derecha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be58ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las violaciones de los márgenes son malas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32abef31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por lo general, es mejor tener algunos de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2cdef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_1/chap_5_sv/figure_5_4.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffd52d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, en este caso, el modelo de la izquierda tiene muchas violaciones de márgenes, pero probablemente generalice mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb05fe04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sugerencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473d2cd1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si su modelo SVM está sobreajustado, puede intentar regularizarlo reduciendo C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a09e92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El siguiente código de Scikit-Learn carga el conjunto de datos de iris, escala las características y luego entrena un modelo SVM lineal (usando la clase LinearSVC con C=1 y la función de pérdida de bisagra, descrita en breve) para detectar flores de Iris virginica:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba04688c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('linear_svc', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "iris = datasets.load_iris()\n",
    "X = iris[\"data\"][:, (2, 3)] # petal length, petal width\n",
    "y = (iris[\"target\"] == 2).astype(np.float64) # Iris virginica\n",
    "svm_clf = Pipeline([\n",
    "(\"scaler\", StandardScaler()),\n",
    "(\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),\n",
    "])\n",
    "svm_clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341fd646",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El modelo resultante se representa a la izquierda en la Figura 5-4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5784a680",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Luego, como de costumbre, puede usar el modelo para hacer predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0de8e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a018a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f1692",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Unlike Logistic Regression classifiers, SVM classifiers do not output probabilities for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424b749",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instead of using the LinearSVC class, we could use the SVC class with a linear kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8733bb98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When creating the SVC model, we would write SVC(kernel=\"linear\", C=1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025b797a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or we could use the SGDClassifier class, with SGDClassifier(loss=\"hinge\",\n",
    "alpha=1/(m*C)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd48092",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This applies regular Stochastic Gradient Descent (see Chapter 4) to train a linear SVM classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df449dea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It does not converge as fast as the LinearSVC class, but it can be useful to handle online classification tasks or huge datasets that do not fit in memory (out-of-core training)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d1dca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144fb29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The LinearSVC class regularizes the bias term, so you should center the training set first by subtracting its mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0396a56e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is automatic if you scale the data using the StandardScaler. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6dac4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Also make sure you set the loss hyperparameter to \"hinge\", as it is not the default value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3a168",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, for better performance, you should set the dual hyperparameter to False, unless there are more features than training instances (we will discuss duality later in the chapter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f233e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nonlinear SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6c149",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Although linear SVM classifiers are efficient and work surprisingly well in many cases, many datasets are not even close to being linearly separable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa157ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One approach to handling nonlinear datasets is to add more features, such as polynomial features (as you did in Chapter 4); in some cases this can result in a linearly separable dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e6300",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider the left plot in Figure 5-5: it represents a simple dataset with just one feature, $x_{1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521b972b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This dataset is not linearly separable, as you can see. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975c2bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But if you add a second feature $x_{2} = (x_{1})^{2}$ , the resulting 2D dataset is perfectly linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b766ef6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb9acd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f847f24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb4761",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77324734",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0017a54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51482f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
