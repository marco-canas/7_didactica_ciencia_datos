{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "np.random.seed(48) \n",
    "X = 2 * np.random.rand(100, 1)          # \n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), X] # add x0 = 1 to each instance\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ver página 108 de clára elena mejía: Aproximación mediante mínimos cuadrados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0117793 ],\n",
       "       [2.92444191]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradiente descendente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aurelien Geron, page 173 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Gradient Descent* es un algoritmo de optimización genérico capaz de encontrar soluciones óptimas a una amplia gama de problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La idea general de Gradient Descent es ajustar los parámetros de forma iterativa para minimizar una función de coste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suponga que está perdido en las montañas en una densa niebla y solo puede sentir la pendiente del suelo debajo de sus pies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una buena estrategia para llegar rápidamente al fondo del valle es descender en dirección a la pendiente más pronunciada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto es exactamente lo que hace Gradient Descent: mide el gradiente local de la función de error con respecto al vector de parámetro $\\theta$, y va en la dirección del gradiente descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una vez que el gradiente es cero, ¡ha alcanzado un mínimo! Concretamente, comienza llenando $\\theta$ con valores aleatorios (esto se llama inicialización aleatoria)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Luego lo mejora gradualmente, dando un pequeño paso a la vez, cada paso intentando disminuir la función de costo (por ejemplo, el MSE), hasta que el algoritmo converja al mínimo (vea la Figura 4-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='figure_4_3.jpg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Un parámetro importante en Gradient Descent es el tamaño de los pasos, determinado por el hiperparámetro de tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si la tasa de aprendizaje es demasiado pequeña, el algoritmo tendrá que pasar por muchas iteraciones para converger, lo que llevará mucho tiempo (consulte la Figura 4-4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='figure_4_4.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por otro lado, si la tasa de aprendizaje es demasiado alta, es posible que salte al otro lado del valle y termine en el otro lado, posiblemente incluso más alto que antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto podría hacer que el algoritmo divergiera, con valores cada vez mayores, sin encontrar una buena solución (consulte la Figura 4-5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='figure_4_5.jpg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por último, no todas las funciones de costos se ven como buenos cuencos normales.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Puede haber huecos, crestas, mesetas y todo tipo de terrenos irregulares, lo que dificulta la convergencia al mínimo. La Figura 4-6 muestra los dos desafíos principales con Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si la inicialización aleatoria inicia el algoritmo de la izquierda, entonces convergerá a un mínimo local, que no es tan bueno como el mínimo global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si comienza por la derecha, llevará mucho tiempo cruzar la meseta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Y si se detiene demasiado pronto, nunca alcanzará el mínimo global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='figure_4_6.jpg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Afortunadamente, la función de costo MSE para un modelo de regresión lineal resulta ser una función convexa, lo que significa que si elige dos puntos cualesquiera en la curva, el segmento de línea que los une nunca cruza la curva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto implica que no hay mínimos locales, solo un mínimo global.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "También es una función continua con una pendiente que nunca cambia abruptamente.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Estos dos hechos tienen una gran consecuencia: se garantiza que Gradient Descent se acercará arbitrariamente a cerrar el mínimo global (si espera lo suficiente y si la tasa de aprendizaje no es demasiado alta)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De hecho, la función de costo tiene la forma de un cuenco, pero puede ser un cuenco alargado si las características tienen escalas muy diferentes.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La Figura 4-7 muestra Gradient Descent en un conjunto de entrenamiento donde las características 1 y 2 tienen la misma escala (a la izquierda), y en un conjunto de entrenamiento donde la característica 1 tiene valores mucho más pequeños que la característica 2 (a la derecha)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='figure_4_7.jpg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como puede ver, a la izquierda el algoritmo Gradient Descent va directo hacia el mínimo, alcanzándolo rápidamente, mientras que a la derecha primero va en una dirección casi ortogonal a la dirección del mínimo global, y termina con una larga marcha. por un valle casi plano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Eventualmente alcanzará el mínimo, pero llevará mucho tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ADVERTENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Al usar Gradient Descent, debe asegurarse de que todas las características tengan una escala similar (por ejemplo, usando la clase StandardScaler de Scikit-Learn), o de lo contrario, la convergencia llevará mucho más tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este diagrama también ilustra el hecho de que entrenar un modelo significa buscar una combinación de parámetros del modelo que minimice una función de costo (sobre el conjunto de entrenamiento)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es una búsqueda en el espacio de parámetros del modelo: cuantos más parámetros tiene un modelo, más dimensiones tiene este espacio y más difícil es la búsqueda: buscar una aguja en un pajar de 300 dimensiones es mucho más complicado que en 3 dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Afortunadamente, dado que la función de costo es convexa en el caso de la regresión lineal, la aguja está simplemente en la parte inferior del cuenco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradiente descendente por lotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para implementar Gradient Descent, debe calcular el gradiente de la función de costo con respecto a cada parámetro del modelo $\\theta_{j}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En otras palabras, debe calcular cuánto cambiará la función de costo si cambia $\\theta_{j}$ solo un poco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A esto se le llama derivada parcial.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es como preguntar \"¿Cuál es la pendiente de la montaña bajo mis pies si miro hacia el este?\" y luego hacer la misma pregunta mirando hacia el norte (y así sucesivamente para todas las demás dimensiones, si puedes imaginar un universo con más de tres dimensiones)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La ecuación 4-5 calcula la derivada parcial de la función de costo con respecto al parámetro $\\theta_{j}$, anotó $\\frac{\\partial}{\\partial \\theta_{j}}MSE(\\mathbf{\\theta})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ecuación 4-5. Derivadas parciales de la función de costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\begin{equation}\\label{4-5}\n",
    "\\frac{\\partial}{\\partial \\theta_{j}}MSE(\\mathbf{\\theta}) = \\frac{2}{m} \\sum_{i = 1}^{m} (\\mathbf{\\theta}^{T}x^{(i)} - y^{(i)} )x_{j}^{(i)}  \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En lugar de calcular estas derivadas parciales individualmente, puede usar la Ecuación 4-6 para calcularlas todas de una vez. El vector de gradiente, denominado $\\nabla_{\\mathbf{\\theta}}MSE(\\mathbf{\\theta})$, contiene todas las derivadas parciales de la función de costo (una para cada parámetro del modelo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ecuación 4-6. Vector de gradiente de la función de costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ \\nabla_{\\mathbf{\\theta}} MSE(\\mathbf{\\theta}) = \\begin{pmatrix} \\frac{\\partial}{\\partial_{\\theta_{0}}}MSE(\\mathbf{\\theta}) \\\\ \\frac{\\partial}{\\partial \\theta_{1}}MSE(\\mathbf{\\theta}) \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial \\theta_{n}}MSE(\\mathbf{\\theta}) \\end{pmatrix} \\frac{2}{m}\\mathbf{X}^{T} (\\mathbf{X}^{T}-y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ADVERTENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tenga en cuenta que esta fórmula implica cálculos sobre el conjunto de entrenamiento completo $\\mathbf{X}$, en cada paso de Gradient Descent.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por eso el algoritmo se llama Descenso de gradiente por lotes: utiliza el lote de datos de entrenamiento en cada paso (en realidad, Full Gradient Descent probablemente sería una mejor\n",
    "nombre)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como resultado, es terriblemente lento en conjuntos de entrenamiento muy grandes (pero veremos algoritmos de Gradient Descent mucho más rápidos en breve)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, Gradient Descent se adapta bien al número de características; entrenar un modelo de regresión lineal cuando hay cientos de miles de entidades es mucho más rápido con el descenso de gradiente que con la ecuación normal o la descomposición de SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una vez que tenga el vector de gradiente, que apunta hacia arriba, simplemente vaya en la dirección opuesta para ir cuesta abajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto significa restar $\\nabla_{\\mathbf{\\theta}}MSE(\\mathbf{\\theta})$ de $\\mathbf{\\theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aquí es donde entra en juego la tasa de aprendizaje $\\eta$: multiplique el vector de gradiente por $\\eta$ para determinar el tamaño del paso cuesta abajo (Ecuación 4-7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Equation 4-7. Gradient Descent step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ \\theta^{(\\text{next step})} =  \\mathbf{\\theta} - \\eta\\nabla_{\\mathbf{\\theta}} MSE(\\mathbf{\\theta}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Veamos una implementación rápida de este algoritmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "eta = 0.1     # learning rate\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "theta = np.random.randn(2,1) # random initialization\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "¡Eso no fue tan difícil! Veamos la ``theta`` resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "theta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "theta_best "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "¡Oye, eso es exactamente lo que encontró la ecuación normal! Gradient Descent funcionó a la perfección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pero, ¿y si hubiera utilizado una tasa eta de aprendizaje diferente?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La Figura 4-8 muestra los primeros 10 pasos de Gradient Descent utilizando tres tasas de aprendizaje diferentes (la línea discontinua representa el punto de partida)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='figure_4_8.jpg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A la izquierda, la tasa de aprendizaje es demasiado baja: el algoritmo finalmente llegará a la solución, pero llevará mucho tiempo.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En el medio, la tasa de aprendizaje parece bastante buena: en solo unas pocas iteraciones, ya ha convergido a la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A la derecha, la tasa de aprendizaje es demasiado alta: el algoritmo diverge, salta por todos lados y, de hecho, se aleja cada vez más de la solución en cada paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para encontrar una buena tasa de aprendizaje, puede utilizar la búsqueda en cuadrícula (consulte el Capítulo 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, es posible que desee limitar el número de iteraciones para que la búsqueda de cuadrícula pueda eliminar los modelos que tardan demasiado en converger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quizás se pregunte cómo establecer el número de iteraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si es demasiado bajo, aún estará lejos de la solución óptima cuando el algoritmo se detenga; pero si es demasiado alto, perderá tiempo mientras los parámetros del modelo ya no cambian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una solución simple es establecer una gran cantidad de iteraciones pero interrumpir el algoritmo cuando el vector de gradiente se vuelve pequeño, es decir, cuando su norma se vuelve más pequeña que un número diminuto $\\epsilon$ (llamado tolerancia), porque esto sucede cuando Gradient Descent tiene (casi) alcanzó el mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TASA DE CONVERGENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando la función de costo es convexa y su pendiente no cambia abruptamente (como es el caso de la función de costo MSE), Batch Gradient Descent con una tasa de aprendizaje fija eventualmente convergerá a la solución óptima, pero es posible que tenga que esperar un poco: puede tomar iteraciones $O(1/\\epsilon)$ para alcanzar el óptimo dentro de un rango de $\\epsilon$, dependiendo de la forma de la función de costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si divide la tolerancia por 10 para tener una solución más precisa, es posible que el algoritmo deba ejecutarse unas 10 veces más."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradiente descendente estocástico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El principal problema con Batch Gradient Descent es el hecho de que utiliza todo el conjunto de entrenamiento para calcular los gradientes en cada paso, lo que lo hace muy lento cuando el conjunto de entrenamiento es grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En el extremo opuesto, Stochastic Gradient Descent elige una instancia aleatoria en el conjunto de entrenamiento en cada paso y calcula los gradientes basándose solo en esa instancia única."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Obviamente, trabajar en una sola instancia a la vez hace que el algoritmo sea mucho más rápido porque tiene muy pocos datos para manipular en cada iteración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "También hace posible entrenar en grandes conjuntos de entrenamiento, ya que solo una instancia necesita estar en la memoria en cada iteración (Stochastic GD se puede implementar como un algoritmo fuera del núcleo; vea el Capítulo 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por otro lado, debido a su naturaleza estocástica (es decir, aleatoria), este algoritmo es mucho menos regular que Batch Gradient Descent: en lugar de disminuir suavemente hasta alcanzar el mínimo, la función de costo rebotará hacia arriba y hacia abajo, disminuyendo solo en promedio.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Con el tiempo terminará muy cerca del mínimo, pero una vez que llegue allí, seguirá rebotando y nunca se asentará (ver\n",
    "Figura 4-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Entonces, una vez que el algoritmo se detiene, los valores finales de los parámetros son buenos,\n",
    "pero no óptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='figure_4_9.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando la función de costo es muy irregular (como en la Figura 4-6), esto puede ayudar al algoritmo a saltar de los mínimos locales, por lo que el Descenso de gradiente estocástico tiene más posibilidades de encontrar el mínimo global que el Descenso de gradiente por lotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por lo tanto, la aleatoriedad es buena para escapar de los óptimos locales, pero mala porque significa que el algoritmo nunca puede establecerse en el mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una solución a este dilema es reducir gradualmente la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Los pasos comienzan siendo grandes (lo que ayuda a avanzar rápidamente y escapar de los mínimos locales), luego se vuelven cada vez más pequeños, lo que permite que el algoritmo se establezca en el mínimo global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este proceso es similar al recocido simulado, un algoritmo inspirado en el proceso de la metalurgia del recocido, donde el metal fundido se enfría lentamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La función que determina la tasa de aprendizaje en cada iteración se llama programa de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si la tasa de aprendizaje se reduce demasiado rápido, puede quedarse atascado en un mínimo local o incluso terminar congelado a la mitad del mínimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si la tasa de aprendizaje se reduce demasiado lentamente, puede saltar alrededor del mínimo durante un tiempo prolongado y terminar\n",
    "con una solución subóptima si dejas de entrenar demasiado pronto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este código implementa el descenso de gradiente estocástico usando un aprendizaje simple\n",
    "calendario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "t0, t1 = 5, 50                      # learning schedule hyperparameters\n",
    "def learning_schedule(t):\n",
    "    return t0 / (t + t1)\n",
    "theta = np.random.randn(2,1)         # random initialization\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_schedule(epoch * m + i)\n",
    "        theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por convención iteramos por rondas de m iteraciones; cada ronda se llama época."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si bien el código Batch Gradient Descent se repitió 1000 veces a través de todo el conjunto de entrenamiento, este código pasa por el conjunto de entrenamiento solo 50 veces y llega a una solución bastante buena:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "theta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La Figura 4-10 muestra los primeros 20 pasos del entrenamiento (observe cuán irregulares son los pasos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='figure_4_10.jpg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tenga en cuenta que, dado que las instancias se seleccionan al azar, algunas instancias pueden elegirse varias veces por época, mientras que otras pueden no seleccionarse en absoluto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si quieres estar seguro de que el algoritmo pasa por cada instancia en cada época, otro enfoque es mezclar el conjunto de entrenamiento (asegurándote de mezclar las características de entrada y las etiquetas de manera conjunta), luego revisarlo instancia por instancia, luego mezclarlo de nuevo, y así sucesivamente. Sin embargo, este enfoque generalmente converge más lentamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ADVERTENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando se utiliza el descenso de gradiente estocástico, las instancias de entrenamiento deben ser independientes y distribuidas de manera idéntica (IID) para garantizar que los parámetros se acerquen al óptimo global, en promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una forma sencilla de garantizar esto es mezclar las instancias durante el entrenamiento (por ejemplo, elegir cada instancia al azar o mezclar el conjunto de entrenamiento al comienzo de cada época)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si no mezcla las instancias, por ejemplo, si las instancias están ordenadas por etiqueta, entonces SGD comenzará optimizando para una etiqueta, luego la siguiente, y así sucesivamente, y no se acercará al mínimo global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para realizar una regresión lineal usando Stochastic GD con Scikit-Learn, puede usar la clase ``SGDRegressor``, que por defecto optimiza la función de costo de error al cuadrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El siguiente código se ejecuta durante un máximo de 1.000 épocas o hasta que la pérdida se reduce en menos de 0,001 durante una época (max_iter = 1000, tol = 1e-3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comienza con una tasa de aprendizaje de 0.1 (eta0 = 0.1), utilizando el programa de aprendizaje predeterminado (diferente al anterior).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por último, no utiliza ninguna regularización (penalización = Ninguna; más detalles sobre esto en breve):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\n",
    "sgd_reg.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una vez más, encuentra una solución bastante cercana a la devuelta por la Ecuación Normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradiente descendente por mini lotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El último algoritmo de Gradient Descent que veremos se llama Gradient Descent por mini lotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es fácil de entender una vez que conoces el descenso de gradiente estocástico y por lotes: en cada paso, en lugar de calcular los gradientes en función del conjunto de entrenamiento completo (como en GD por lotes) o en una sola instancia (como en GD estocástico), Mini- El GD por lotes calcula los gradientes en pequeños conjuntos aleatorios de instancias llamados mini lotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La principal ventaja de Mini-batch GD sobre Stochastic GD es que puede obtener un aumento del rendimiento de la optimización del hardware de las operaciones matriciales, especialmente cuando se utilizan GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El progreso del algoritmo en el espacio de parámetros es menos errático que con Stochastic GD, especialmente con mini-lotes bastante grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Como resultado, el GD de mini lotes terminará caminando un poco más cerca del mínimo que el GD estocástico, pero puede ser más difícil para él escapar de los mínimos locales (en el caso de problemas que sufren de mínimos locales, a diferencia de la regresión lineal )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La figura 4-11 muestra las rutas tomadas por los tres algoritmos de descenso de gradiente en el espacio de parámetros durante\n",
    "formación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Todos terminan cerca del mínimo, pero el camino de Batch GD en realidad se detiene en el mínimo, mientras que Stochastic GD y Mini-batch GD continúan caminando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, no olvide que Batch GD requiere mucho tiempo para dar cada paso, y Stochastic GD y Mini-batch GD también alcanzarían el mínimo si utilizara un buen programa de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='figure_4_11.jpg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Comparemos los algoritmos que hemos discutido hasta ahora para la regresión lineal (recuerde que m es el número de instancias de entrenamiento y n es el número de características); consulte la Tabla 4-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('table_4_1.JPG',width=600,height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NOTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Casi no hay diferencia después del entrenamiento: todos estos algoritmos terminan con modelos muy similares y hacen predicciones exactamente de la misma manera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Page 186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "rise": {
   "enable_chalkboard": true,
   "theme": "sky",
   "transition": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
