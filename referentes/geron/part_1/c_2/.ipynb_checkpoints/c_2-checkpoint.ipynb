{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e38419a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_1/c_2/c_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b732c7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [Video de apoyo a la lectura de esta clase](https://www.youtube.com/watch?v=4JDqj1NT4Qk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32057e54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modelo de regresión para predicción de precio de vivienda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c2b73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objetivo\n",
    "\n",
    "* Construir un modelo de regresión para la predicción de precio de vivienda siguiendo la metodología de Aurelien Geron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c95a2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Metodología de modelamiento para Machine Learning de Geron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b550c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Plantear, de manera justificada, la pregunta.\n",
    "   * ¿Regresión o clasificación?\n",
    "   * ¿Tipo de regresión y tipo de clasificación?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b455d2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. Exploración inicial.\n",
    "   * Indicar la fuente de dónde se toman los datos.\n",
    "   * Hacer explícita la función objetivo.\n",
    "   * Decir cuáles son los atributos (descripción breve de cada uno)\n",
    "   * Practicar una primera exploración gráfica de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed4e59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. Preparar los datos para los algoritmos de aprendizaje.\n",
    "   * Hacer separación inicial de datos para entrenar y para testear.\n",
    "   * Explorar correlaciones lineales con la variable objetivo.\n",
    "   * Eliminar de ser necesario atributos que no sean de mucha utilidad.\n",
    "   * Limpiar datos y llenar datos faltantes.\n",
    "   * Estandarizar los datos.\n",
    "   * Crear funciones en Python de manera que se puedan replicar los procesos de transformación de datos en proyectos nuevos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd86f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4. Entrenamiento y selección de modelo.\n",
    "   * Instanciar varios modelos y entrenarlos sobre datos de entrenamiento preparados.\n",
    "   * Medir el desempeño de varios modelos (comparativa, con la técnica de la validación cruzada)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9359e3a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5. Afinar el modelo.\n",
    "   * Crear cuadrícula (de búsqueda) de hiperparámetros.\n",
    "   * Seleccionar la combinación de hiperparámetros que consigue el mejor puntaje. (El mejor modelo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd844837",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "6. Presentar la solución.\n",
    "   * Mostrar el desempeño sobre los datos para testear.\n",
    "   * (Opcional) Gráfico intuitivo para representar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6f4d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[Video de apoyo sobre presentación de la metodología para modelo de machine Learning](https://www.youtube.com/watch?v=blRXFU2KooI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dabd3a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Implementación del plan "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a125c13a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Plantear bien la pregunta.\n",
    "   * ¿Regresión o clasificación?\n",
    "   * ¿Tipo de regresión y tipo de clasificación?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d121d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tenemos un dataset con la siguiente configuración: $[X|y]$.  \n",
    "\n",
    "$X = [x_{ij}] \\in \\mathbb{R}_{n,d}$.  \n",
    "$X^{j}$: $j$ ésimo atributo.   \n",
    "$X_{i}$: $i$ ésima fila o instancia ($i$ -ésimo distrito)  \n",
    "$x_{ij}$: $ij$ ésima entrada de la matriz $X$.   \n",
    "$y = [y_{i}] \\in \\mathbb{R}^{n}$: el vector de los valores promedios de vivienda.  \n",
    "$y_{i}$ el valor promedio de vivienda en el $i$ ésimo distrito"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f160fcc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este es un problema de regresión porque lo que se trata es de predecir un valor o la función predictora de valor continuo o de valores en un intervalo de números reales. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abb1b2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El tipo de regresión es lineal porque \n",
    "\n",
    "$$h_{w}(X_{i}) = y_{i} = w^{T}X_{i} = w \\cdot X_{i} = w_{0} + w_{1}x_{i1} + \\cdots + w_{d}x_{id} $$ \n",
    "$$ = \\begin{pmatrix} w_{0} \\\\ w_{1} \\\\ \\vdots \\\\ w_{d} \\end{pmatrix} \\cdot \\begin{pmatrix} 1 \\\\ x_{i1} \\\\ \\cdots \\\\ x_{id} \\end{pmatrix} $$\n",
    "\n",
    "donde $d$ es el número de atributos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61421d22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Exploración inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a924e190",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Indicar la fuente de dónde se toman los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc551fa5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Su primera tarea es utilizar los datos del censo de California para construir un modelo de precios de viviendas en el estado.\n",
    "\n",
    "Estos datos incluyen métricas como la población, el ingreso medio y el precio medio de la vivienda para cada grupo de bloques en California.\n",
    "\n",
    "Los grupos de bloques son la unidad geográfica más pequeña para la que la Oficina del Censo de EE. UU. publica datos de muestra (un grupo de bloques suele tener una población de 600 a 3000 personas).\n",
    "\n",
    "Los llamaremos “distritos” para abreviar.\n",
    "\n",
    "Su modelo debe aprender de estos datos y poder predecir el precio medio de la vivienda en cualquier distrito, dadas todas las demás métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32d9be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hacer explícita la función objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0909354",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$ h:\\mathbb{R}^{9} \\to \\mathbb{R} $$\n",
    "\n",
    "$$ h(X_{n \\times d}) = y $$\n",
    "\n",
    "donde $X$ es una matriz alta (número de filas mucho mayor al número de columnas). \n",
    "\n",
    "$y$ es un vector de $\\mathbb{R}^{m}$ cuyas entradas son los precios promedio de vivienda por distrito. \n",
    "\n",
    "$$ h(X_{i}) = y_{i} \\in \\mathbb{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d4452",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decir cuáles son los atributos (descripción breve de cada uno)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c429a5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Son nueve atributos o variables predictoras entre las que están:\n",
    "\n",
    "* longitud\n",
    "* latitud\n",
    "* habitaciones\n",
    "* dormitorios\n",
    "* ingresos promedio\n",
    "* proximidad al oceano\n",
    "* antiguedad promedio de las viviendas en el distrito.\n",
    "* Número de hogares\n",
    "* población\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000eef6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## [Video de apoyo]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b3320",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Practicar una primera exploración gráfica de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa4a36",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31236055",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v = pd.read_csv('vivienda.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e322862",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9b7d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.head(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b808f05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cb213f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a231f859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hay `20_640` instancias en el conjunto de datos, lo que significa que es bastante pequeño para los estándares de Machine Learning, pero es perfecto para comenzar. Tenga en cuenta que el atributo total_bedrooms solo tiene 20 433 valores no nulos, lo que significa que 207 distritos no tienen esta función. Tendremos que ocuparnos de esto más tarde."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c7355",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Todos los atributos son numéricos, excepto el campo `ocean_proximity`. Su tipo es objeto, por lo que podría contener cualquier tipo de objeto de Python. Pero dado que cargó estos datos desde un archivo CSV, sabe que debe ser un atributo de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cafebdd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando miró las cinco filas superiores, probablemente notó que los valores en la columna ocean_proximity eran repetitivos, lo que significa que probablemente sea un atributo categórico. Puede averiguar qué categorías existen y cuántos distritos pertenecen a cada categoría usando el método `value_counts()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402778d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inferencias e interpretaciones de la sintesis obtenida con el método `.info()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28a2037",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.proximidad.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d58ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a1019",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "v.hist(figsize = (20,10))\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff28400c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualización de datos geográficos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830cd5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.plot(kind = 'scatter', x = 'longitud', y = 'latitud', alpha = 0.8)\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903ff0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.plot(kind = 'scatter', x = 'longitud', y = 'latitud', alpha = 0.1) \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e66778",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.plot(kind = 'scatter', x = 'longitud', y = 'latitud', alpha = 0.4, \\\n",
    "      s = v.población/100, label = 'Población', \\\n",
    "      c = 'precio', cmap = plt.get_cmap('jet'), colorbar = True, figsize = (12, 8))  \n",
    "\n",
    "# s de size o tamaño del punto. \n",
    "plt.savefig('california_4D.jpg')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab26c5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Preparar los datos para los algoritmos de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb8da33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hacer separación inicial de datos para entrenar y para testear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda418f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.random.seed(42) \n",
    "# establecer una semilla aleatoria para hacer \n",
    "# reproducible la separación o muestreo aleatorio\n",
    "\n",
    "def dividir_entrenamiento_testeo(datos, porcentaje_testeo):\n",
    "    indices_reordenados = np.random.permutation(len(datos))\n",
    "    tamaño_conjunto_testeo = int(len(datos)*porcentaje_testeo)\n",
    "    indices_testeo = indices_reordenados[:tamaño_conjunto_testeo]\n",
    "    indices_entrenamiento = indices_reordenados[tamaño_conjunto_testeo:]\n",
    "    return datos.iloc[indices_entrenamiento], datos.iloc[indices_testeo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1e642",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_train, v_test = dividir_entrenamiento_testeo(v, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50464f89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "len(v_train), len(v_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc8ce4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "len(v_train)+ len(v_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f4948",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "len(v_train)/len(v_test) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afe329",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Separación del dataset en entrenamiento y testeo usando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d6016",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "v_train, v_test = train_test_split(v, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f93928",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De ahora en adelante se seguirá es procesando a los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45838f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Limpiar datos y llenar datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1f346",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mediana  = v.dormitorios.median() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c121564",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mediana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b17ed2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.dormitorios.fillna(mediana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3e891",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "len(pd.DataFrame(v.dormitorios.fillna(mediana)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d194e06",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Imputación de datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cedf25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdbd3bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "imputado = SimpleImputer(strategy = 'median') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615edebb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_num = v.drop(['proximidad'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c36b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "imputado.fit(v_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ba175",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = imputado.fit_transform(v_num) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe62e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_num_imputado = pd.DataFrame(X,\\\n",
    "                     columns = v_num.columns, \\\n",
    "                     index = v_num.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e0b51a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_num_imputado.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1406ff73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Explorar correlaciones lineales con la variable objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2132753",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/Correlation_examples2.svg/759px-Correlation_examples2.svg.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182f525",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.corr() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780c1c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.corr().precio.sort_values(ascending = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b9e6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37d47e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Eliminar de ser necesario atributos que no sean de mucha utilidad. Ingeniería de atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7799c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experimentación con combinación de atributos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99efa00",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una última cosa que quizás desee hacer antes de preparar los datos para los algoritmos de Machine Learning es probar varias combinaciones de atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003368d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por ejemplo, el número total de habitaciones en un distrito no es muy útil si no sabe cuántos hogares hay. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b279404",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lo que realmente desea es el número de habitaciones por hogar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11efbaf5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Del mismo modo, el número total de dormitorios por sí solo no es muy útil: probablemente quieras compararlo con el número de habitaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3092ec09",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Y la población por hogar también parece una combinación de atributos interesante para observar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e743c1b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vamos a crear estos nuevos atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad283be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c3815",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v[\"habitaciones_por_hogar\"] = v[\"habitaciones\"]/v[\"hogares\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f208756",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v[\"población_por_hogar\"] = v[\"población\"]/v[\"hogares\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a009333",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v['dormitorios_por_habitacion'] = v.dormitorios/v.habitaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf9826",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix = v.corr()\n",
    "corr_matrix['precio'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14667cba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Manipulación de datos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c161c5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_cat = v[['proximidad']] \n",
    "# Recuerde que la clase OrdinalEncoder exige que el atributo categórico se entregue \n",
    "#en la forma de arreglo 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89daf34d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098aaa03",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing  import OrdinalEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454c6d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072a7b20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_cat_codificado = ordinal_encoder.fit_transform(v_cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93727d51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_cat_codificado[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3420140",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformadores personalizados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa765e9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aunque Scikit-Learn proporciona muchos transformadores útiles, deberá escribir los suyos propios para tareas como operaciones de limpieza personalizadas o combinación de atributos específicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd2484",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Querrá que su transformador funcione a la perfección con las funcionalidades de Scikit-Learn (como las canalizaciones), y dado que Scikit-Learn se basa en la tipificación pato (no en la herencia), todo lo que necesita hacer es crear una clase e implementar tres métodos:  \n",
    "\n",
    "* `fit()` (retornando a sí mismo),\n",
    "* `transform()`, y\n",
    "* `fit_transform()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc608eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Puede obtener el último de forma gratuita simplemente agregando `TransformerMixin` como clase base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4802a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si agrega `BaseEstimator` como clase base (y evita `*args` y `**kargs` en su constructor), también obtendrá dos métodos adicionales (`get_params()` y `set_params()`) que ser útil para el ajuste automático de hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded3192",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por ejemplo, aquí hay una pequeña clase de transformador que agrega los atributos combinados que discutimos anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d2e27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0a8bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94fb1a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "         self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self               # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb82b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1732e9a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_extra_attribs = attr_adder.transform(v_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49167123",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_extra_attribs_df = pd.DataFrame(v_extra_attribs, \\\n",
    "                                  columns = list(v_train.columns) + ['habitaciones_por_hogar', 'población_por_hogar'],\\\n",
    "                                 index = v_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c0531",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "v_extra_attribs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52df997",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En este ejemplo, el transformador tiene un hiperparámetro, `add_bedrooms_per_room`, establecido en True de forma predeterminada (a menudo es útil proporcionar valores predeterminados sensibles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fee2bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este hiperparámetro le permitirá averiguar fácilmente si agregar este atributo ayuda o no a los algoritmos de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e8e20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More generally, you can add a hyperparameter to gate any data preparation step that you are not 100% sure about. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040a114",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The more you automate these data preparation steps, the more combinations you can automatically try out, making it much more likely that you will find a great combination (and saving you a lot of time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af82470",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fefb4bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One of the most important transformations you need to apply to your data is feature scaling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ec8bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With few exceptions, Machine Learning algorithms don’t perform well when the input numerical attributes have very different scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5407fe5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is the case for the housing data: the total number of rooms ranges from about 6 to 39,320, while the median incomes only range from 0 to 15. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3108f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that scaling the target values is generally not required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b80436",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are two common ways to get all attributes to have the same scale: min-max scaling and standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa4c0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Min-max scaling (many people call this normalization) is the simplest: values are shifted and rescaled so that they end up ranging from 0 to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044f872",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We do this by subtracting the min value and dividing by the max minus the min. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2bc960",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-Learn provides a transformer called MinMaxScaler for this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61858d44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It has a feature_range hyperparameter that lets you change the range if, for some reason, you don’t want 0–1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650801c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Standardization is different: first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation so that the resulting distribution has unit variance. Unlike min-max scaling,\n",
    "standardization does not bound values to a specific range, which may be a\n",
    "problem for some algorithms (e.g., neural networks often expect an input value\n",
    "ranging from 0 to 1). However, standardization is much less affected by\n",
    "outliers. For example, suppose a district had a median income equal to 100 (by\n",
    "mistake). Min-max scaling would then crush all the other values from 0–15\n",
    "down to 0–0.15, whereas standardization would not be much affected. Scikit-Learn provides a transformer called StandardScaler for standardization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18786d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5444c54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As with all the transformations, it is important to fit the scalers to the training data only, not to the full dataset (including the test set). Only then can you use them to transform the training set and the test set (and new data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c7e354",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformation Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b50d48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As you can see, there are many data transformation steps that need to be executed in the right order. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb751e7d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fortunately, Scikit-Learn provides the Pipeline class to help with such sequences of transformations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e535343",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aquí hay una pequeña tubería para los atributos numéricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d68af2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "('imputer', SimpleImputer(strategy=\"median\")),\n",
    "('attribs_adder', CombinedAttributesAdder()),\n",
    "('std_scaler', StandardScaler()),\n",
    "])\n",
    "v_num_tr = num_pipeline.fit_transform(v_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb4800",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Pipeline constructor takes a list of name/estimator pairs defining a sequence of steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90db8131",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All but the last estimator must be transformers (i.e., they must have a `fit_transform()` method). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf27eb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The names can be anything you like (as long as they are unique and don’t contain double underscores, __); they will\n",
    "come in handy later for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1508d86",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When you call the pipeline’s fit() method, it calls fit_transform() sequentially on all transformers, passing the output of each call as the parameter to the next call until it reaches the final estimator, for which it calls the fit()\n",
    "method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f87c953",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The pipeline exposes the same methods as the final estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a052512",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this example, the last estimator is a `StandardScaler`, which is a transformer, so the pipeline has a `transform()` method that applies all the transforms to the data in sequence (and of course also a `fit_transform()` method, which is the one we\n",
    "used)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7776bad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So far, we have handled the categorical columns and the numerical columns\n",
    "separately. It would be more convenient to have a single transformer able to\n",
    "handle all columns, applying the appropriate transformations to each column. In\n",
    "version 0.20, Scikit-Learn introduced the ColumnTransformer for this purpose,\n",
    "and the good news is that it works great with pandas DataFrames. Let’s use it to\n",
    "apply all the transformations to the housing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc212d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "num_attribs = list(v_train_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "full_pipeline = ColumnTransformer([\n",
    "(\"num\", num_pipeline, num_attribs),\n",
    "(\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "v_prepared = full_pipeline.fit_transform(v_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dff638",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First we import the ColumnTransformer class, next we get the list of numerical\n",
    "column names and the list of categorical column names, and then we construct\n",
    "a ColumnTransformer. The constructor requires a list of tuples, where each\n",
    "tuple contains a name, a transformer, and a list of names (or indices) of\n",
    "columns that the transformer should be applied to. In this example, we specify\n",
    "that the numerical columns should be transformed using the num_pipeline that\n",
    "we defined earlier, and the categorical columns should be transformed using a\n",
    "OneHotEncoder. Finally, we apply this ColumnTransformer to the housing\n",
    "data: it applies each transformer to the appropriate columns and concatenates the outputs along the second axis (the transformers must return the same\n",
    "number of rows)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c0850",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the OneHotEncoder returns a sparse matrix, while the num_pipeline returns a dense matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70992482",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When there is such a mix of sparse and dense matrices,\n",
    "the ColumnTransformer estimates the density of the final matrix (i.e., the ratio\n",
    "of nonzero cells), and it returns a sparse matrix if the density is lower than a\n",
    "given threshold (by default, sparse_threshold=0.3). In this example, it\n",
    "returns a dense matrix. And that’s it! We have a preprocessing pipeline that\n",
    "takes the full housing data and applies the appropriate transformations to each\n",
    "column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3490dd6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4ad07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instead of using a transformer, you can specify the string \"drop\" if you want the columns to be dropped, or you can specify \"passthrough\" if you want the columns to be left untouched."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8221d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "By default, the remaining columns (i.e., the ones that were not listed) will be dropped, but\n",
    "you can set the remainder hyperparameter to any transformer (or to \"passthrough\") if you\n",
    "want these columns to be handled differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa5742",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you are using Scikit-Learn 0.19 or earlier, you can use a third-party library\n",
    "such as sklearn-pandas, or you can roll out your own custom transformer to\n",
    "get the same functionality as the ColumnTransformer. Alternatively, you can\n",
    "use the FeatureUnion class, which can apply different transformers and\n",
    "concatenate their outputs. But you cannot specify different columns for each\n",
    "transformer; they all apply to the whole data. It is possible to work around this\n",
    "limitation using a custom transformer for column selection (see the Jupyter\n",
    "notebook for an example)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd138a34",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Select and Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9279f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "At last! You framed the problem, you got the data and explored it, you sampled a training set and a test set, and you wrote transformation pipelines to clean up and prepare your data for Machine Learning algorithms automatically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65803f62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You are now ready to select and train a Machine Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56580779",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training and Evaluating on the Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed39d453",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The good news is that thanks to all these previous steps, things are now going to be much simpler than you might think. Let’s first train a Linear Regression model, like we did in the previous chapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f789c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(v_train_prepared, v_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5cce0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "rise": {
   "enable_chalkboard": true,
   "theme": "sky",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
