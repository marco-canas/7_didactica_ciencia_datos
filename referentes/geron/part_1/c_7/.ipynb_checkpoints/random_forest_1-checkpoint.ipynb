{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fb4b694",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/Machine-Learning/blob/main/ML/classes/class_march_3/class_march_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc43d18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Chapter 7. Ensemble Learning and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6345d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suponga que plantea una pregunta compleja a miles de personas aleatorias y luego agrega sus respuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a7f1db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In many cases you will find that this aggregated answer is better than an expert’s answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a32ab5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is called the wisdom of the crowd. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ea3d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Similarly, if you aggregate the predictions of a group of predictors (such as classifiers or regressors), you will often get better predictions than with the best individual predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f7914",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A group of predictors is called an ensemble; thus, this technique is called Ensemble Learning, and an Ensemble Learning algorithm is called an Ensemble method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ebd59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As an example of an Ensemble method, you can train a group of Decision Tree classifiers, each on a different random subset of the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce9801",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To make predictions, you obtain the predictions of all the individual trees, then predict the class that gets the most votes (see the last exercise in Chapter 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0ed5f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Such an ensemble of Decision Trees is called a Random Forest, and despite its simplicity, this is one of the most powerful Machine Learning algorithms available today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d638ace9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As discussed in Chapter 2, you will often use Ensemble methods near the end of a project, once you have already built a few good predictors, to combine them into an even better predictor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0051b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De hecho, las soluciones ganadoras en las competencias de aprendizaje automático a menudo involucran varios métodos Ensemble (el más famoso en la competencia del Premio Netflix)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab5169",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this chapter we will discuss the most popular Ensemble methods, including bagging, boosting, and stacking. We will also explore Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b2ca9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Voting Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095c80b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Suppose you have trained a few classifiers, each one achieving about 80% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178ad6ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You may have a Logistic Regression classifier, an SVM classifier, a Random Forest classifier,\n",
    "a K-Nearest Neighbors classifier, and perhaps a few more (see Figure 7-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebabcd72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "figura 7.1 \n",
    "<img src = ''>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893859c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A very simple way to create an even better classifier is to aggregate the predictions of\n",
    "each classifier and predict the class that gets the most votes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42fecdd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This majority-vote classifier is called a hard voting classifier (see Figure 7-2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c909c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3499a07b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f4810",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ddb2e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea789a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e86b8e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
