{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6381fb7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/c_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647bc3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Capítulo 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdc194",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introducción a las Redes Artificiales con Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc8194",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Los pájaros nos inspiraron a volar,   \n",
    "* las plantas de bardana inspiraron el velcro y   \n",
    "* la naturaleza ha inspirado innumerables inventos más."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1b25c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://i.blogs.es/1a9d2d/aves-colibri/1366_2000.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1cecae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://www.yateenteraste.mx/wp-content/uploads/2021/05/velcro-origen.jpg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39b2f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Parece lógico, entonces, observar la arquitectura del cerebro en busca de inspiración sobre cómo construir una máquina inteligente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81ebfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://www.analyticslane.com/storage/2018/05/redneuronal.png.webp'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bfd0bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esta es la lógica que desencadenó las redes neuronales artificiales (ANN): \n",
    "* una ANN es un modelo de aprendizaje automático inspirado en las redes de neuronas biológicas que se encuentran en nuestros cerebros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694fd04b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, aunque los aviones se inspiraron en las aves, no es necesario que aleteen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45f0da9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De manera similar, las ANN se han vuelto gradualmente bastante diferentes de sus primos biológicos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b25e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Algunos investigadores incluso argumentan que deberíamos abandonar la analogía biológica por completo   \n",
    "\n",
    "* (por ejemplo, diciendo **\"unidades\"** en lugar de **\"neuronas\"**), para no restringir nuestra creatividad a sistemas biológicamente plausibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916f43d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las ANN están en el centro mismo del Aprendizaje Profundo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270212c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Son versátiles, potentes y escalables,   \n",
    "* lo que los hace ideales para abordar tareas de aprendizaje automático grandes y muy complejas,   \n",
    "* como clasificar miles de millones de imágenes (por ejemplo, imágenes de Google),   \n",
    "* potenciar los servicios de reconocimiento de voz (por ejemplo, **Siri de Apple**),  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f966c1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "* **recomendar los mejores videos** para ver a cientos de millones de usuarios todos los días (por ejemplo, YouTube),   \n",
    "* o **aprender a vencer** al campeón mundial en el juego de Go (AlphaGo de DeepMind)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bfb384",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* La primera parte de este capítulo presenta las redes neuronales artificiales,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee0fe0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   \n",
    "* comenzando con un recorrido rápido por las primeras arquitecturas ANN y  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7125be0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " \n",
    "* llegando a los **perceptrones multicapa (MLP)**, que se usan mucho en la actualidad (se explorarán otras arquitecturas en los próximos capítulos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a8deb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "En la segunda parte, veremos cómo implementar redes neuronales utilizando la popular **API de Keras**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989adde7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esta es una API de alto nivel simple y bellamente diseñada para  \n",
    "* construir, \n",
    "* entrenar, \n",
    "* evaluar y \n",
    "* ejecutar redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9857ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pero no se deje engañar por su simplicidad:  \n",
    "\n",
    "* es lo suficientemente expresiva y flexible como para permitirle construir una amplia variedad de **arquitecturas de redes neuronales**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c429206",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De hecho, probablemente sea suficiente para la mayoría de sus casos de uso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a2594",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Y si alguna vez necesita flexibilidad adicional, siempre puede escribir componentes Keras personalizados utilizando su API de nivel inferior, como veremos en el Capítulo 12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ecad3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pero primero,   \n",
    "¡retrocedamos en el tiempo para ver cómo surgieron las redes neuronales artificiales!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7f873",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# De las neuronas biológicas a las artificiales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1ac33b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Sorprendentemente, las ANN existen desde hace bastante tiempo:   \n",
    "* fueron introducidas por primera vez en **1943**  \n",
    "* por el neurofisiólogo Warren McCulloch y el matemático Walter Pitts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35104831",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = 'https://assets.sutori.com/user-uploads/image/1870cf05-f8d7-40a0-b52f-cea134f9b7ed/ee6d12a3f3f1a26eb09a344949db76b9.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b25b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En su artículo histórico \"Un cálculo lógico de ideas inmanentes en la actividad nerviosa\",  \n",
    "\n",
    "* McCulloch y Pitts presentaron un modelo computacional simplificado de cómo las neuronas biológicas podrían trabajar juntas en cerebros de animales para realizar cálculos complejos utilizando la **lógica proposicional**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9172e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esta fue la primera arquitectura de red neuronal artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd68ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Desde entonces se han inventado muchas otras arquitecturas, como veremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2423c86b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Los primeros éxitos de las ANN llevaron a **la creencia** generalizada de que   \n",
    "* **pronto estaríamos conversando con máquinas verdaderamente inteligentes**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0fc049",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando quedó claro en la década de **1960** que **esta promesa no se cumpliría**  \n",
    "* (al menos durante bastante tiempo), la financiación se fue a otra parte y las ANN entraron en un largo invierno."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f00d1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A principios de la década de **1980**, \n",
    "* se inventaron **nuevas arquitecturas** y \n",
    "* se desarrollaron **mejores técnicas de entrenamiento**, \n",
    "* lo que provocó un resurgimiento del interés por el **conexionismo** (el estudio de las redes neuronales)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb6ab3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pero el progreso fue lento, y en la década de **1990** se inventaron otras poderosas técnicas de aprendizaje automático,   \n",
    "* como **las máquinas de soporte vectorial** (consulte el Capítulo 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196b58b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Estas técnicas parecían ofrecer mejores resultados y bases teóricas más sólidas que las ANN,   \n",
    "* por lo que una vez más se suspendió el estudio de las redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ec9dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ahora estamos presenciando otra ola de interés en las ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb6b6e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "¿Se extinguirá esta ola como lo hicieron las anteriores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144e48d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bueno, aquí hay algunas buenas razones para creer que esta vez es diferente y que \n",
    "* el renovado interés en las RNA tendrá un **impacto mucho más profundo en nuestras vidas**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f629b6ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Ahora hay una **gran cantidad de datos disponibles** para entrenar redes neuronales, \n",
    "* y **las ANN con frecuencia superan a otras técnicas de ML** en problemas muy grandes y complejos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9958f85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* El tremendo **aumento en el poder de cómputo** desde la década de 1990 ahora hace posible entrenar grandes redes neuronales en una cantidad de tiempo razonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0fbc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Esto se debe en parte a la **ley de Moore** (la cantidad de componentes en los circuitos integrados se ha duplicado aproximadamente cada 2 años durante los últimos 50 años),  \n",
    "* pero también gracias a la industria del juego, que ha estimulado la producción de potentes **tarjetas GPU** por millones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dfec1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Además, **las plataformas en la nube** han hecho que este poder sea accesible para todos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd252b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Se han mejorado **los algoritmos de entrenamiento**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3de1b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Para ser justos, son solo ligeramente diferentes de los que se usaron en la década de 1990, pero estos ajustes relativamente pequeños han tenido un gran impacto positivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b06609",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Algunas limitaciones teóricas de las ANN han resultado ser benignas en la práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c736462",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por ejemplo, muchas personas pensaron que los algoritmos de entrenamiento ANN estaban condenados porque era probable que se quedaran atascados en **los óptimos locales**,   \n",
    "* pero resulta que esto es bastante raro en la práctica (y cuando es el caso, por lo general son bastante parecidos a los óptimos globales)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c19ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las ANN parecen haber entrado en un **círculo virtuoso de financiación y progreso**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af808279",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Los productos sorprendentes basados en ANN aparecen regularmente en los **titulares de las noticias**,   \n",
    "* lo que atrae cada vez más atención y financiamiento hacia ellos, lo que resulta en más y más progresos y productos aún más sorprendentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1629102",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neuronas biológicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44430361",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Antes de hablar de las neuronas artificiales, echemos un vistazo rápido a una neurona biológica (representada en la figura 10-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8502fd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/figure_10_1.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3cbc1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es una célula de aspecto inusual que se encuentra principalmente en el cerebro de los animales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33239ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Está compuesto por  \n",
    "\n",
    "* un cuerpo celular que contiene **el núcleo** y la mayoría de los componentes complejos de la célula, \n",
    "\n",
    "* muchas extensiones ramificadas llamadas **dendritas**,   \n",
    "\n",
    "* más una extensión muy larga llamada **axón**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4bee7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La longitud del axón puede ser solo unas pocas veces más larga que el cuerpo celular, o   \n",
    "* hasta decenas de miles de veces más larga."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80718fd0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Cerca de su extremo, el axón se divide en muchas ramas llamadas **telodendrias**, y\n",
    "* en la punta de estas ramas hay estructuras minúsculas llamadas **terminales sinápticas** (o simplemente sinapsis),   \n",
    "* que están conectadas a las dendritas o cuerpos celulares de otras neuronas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b72f41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las neuronas biológicas producen impulsos eléctricos cortos llamados potenciales de acción (AP, o simplemente señales)  \n",
    "* que viajan a lo largo de los axones y hacen que las sinapsis liberen señales químicas llamadas neurotransmisores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18730164",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando una neurona recibe una cantidad suficiente de estos neurotransmisores en unos pocos milisegundos, dispara sus propios impulsos eléctricos   \n",
    "\n",
    "* (en realidad, depende de los neurotransmisores, ya que algunos de ellos inhiben el disparo de la neurona)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa315749",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Por lo tanto, las neuronas biológicas individuales parecen comportarse de una manera bastante simple, \n",
    "* pero están organizadas en una vasta red de miles de millones, con cada neurona típicamente conectada a miles de otras neuronas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942101c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una red de neuronas bastante simples puede realizar cálculos muy complejos,   \n",
    "* al igual que un hormiguero complejo puede surgir de los esfuerzos combinados de hormigas simples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f975a33c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = 'https://previews.123rf.com/images/dualororua/dualororua1706/dualororua170600607/80383774-ilustraci%C3%B3n-vectorial-de-colonia-de-hormigas-de-dibujos-animados-con-hormiguero.jpg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca6847f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La arquitectura de las redes neuronales biológicas (BNN, por sus siglas en inglés) sigue siendo objeto de investigación activa,   \n",
    "* pero se han mapeado algunas partes del cerebro y parece que las neuronas a menudo se organizan en capas consecutivas, especialmente en la corteza cerebral (es decir, la capa externa de su cerebro), como se muestra en la figura 10-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b07d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/figure_10_2.jpg?raw=true'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db42db83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cálculos lógicos con neuronas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f571b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **McCulloch y Pitts** propusieron un modelo muy simple de neurona biológica, que más tarde se conoció como **neurona artificial**: \n",
    "* tiene una o más entradas binarias (on/off) y una salida binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423966cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La neurona artificial activa su salida cuando más de un cierto número de sus entradas están activas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9f1809",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En su artículo, demostraron que, incluso con un modelo tan simplificado, es posible construir una red de neuronas artificiales que calcule cualquier proposición lógica que desee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44367f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para ver cómo funciona una red de este tipo, construyamos algunas ANN que realicen varios cálculos lógicos (consulte la figura 10-3), \n",
    "* suponiendo que una neurona se activa cuando al menos dos de sus entradas están activas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa93e12b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/figure_10_3.jpg?raw=true'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3ed4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Veamos qué hacen estas redes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f667262",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La primera red de la izquierda es **la función de identidad**: \n",
    "* si se activa la neurona A, también se activa la neurona C (ya que recibe dos señales de entrada de la neurona A);  \n",
    "* pero si la neurona A está apagada, entonces la neurona C también lo está."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00425fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La segunda red realiza **un AND lógico**: \n",
    "* la neurona C se activa solo cuando las neuronas A y B están activadas \n",
    "* (una sola señal de entrada no es suficiente para activar la neurona C)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972015f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La tercera red realiza un **OR lógico**: \n",
    "* la neurona C se activa si se activa la neurona A o la neurona B (o ambas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cddc43",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finalmente, si suponemos que una conexión de entrada puede inhibir la actividad de la neurona (que es el caso de las neuronas biológicas), entonces   \n",
    "* la cuarta red calcula una proposición lógica un poco más compleja: la neurona C se activa solo si la neurona A está activa y la neurona B está apagada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c0c555",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si la neurona A está activa todo el tiempo, obtienes **un NO lógico**:   \n",
    "* la neurona C está activa cuando la neurona B está apagada, y viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3307101",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Puede imaginar cómo se pueden combinar estas redes para calcular expresiones lógicas complejas   \n",
    "* (vea los ejercicios al final del capítulo para ver un ejemplo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a80e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866f7c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El Perceptron es una de las arquitecturas ANN más simples,   \n",
    "* inventada en 1957 por Frank Rosenblatt.\n",
    "<img src = 'https://s3.amazonaws.com/s3.timetoast.com/public/uploads/photo/9917116/image/4d8988a1ce02e291141f7d7d9e944366'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811378ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'http://blog.josemarianoalvarez.com/wp-content/uploads/2018/06/ModeloPerceptron-1024x592.jpeg'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003176c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Se basa en una neurona artificial ligeramente diferente (consulte la figura 10-4)   \n",
    "* denominada **unidad lógica de umbral (TLU)** o, a veces, \n",
    "* **unidad de umbral lineal (LTU)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb05a3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Las entradas y salidas son números** (en lugar de valores binarios de encendido/apagado), \n",
    "* y cada **conexión de entrada está asociada con un peso**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a031ffe9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La TLU calcula una suma ponderada de sus entradas \n",
    "\n",
    "$$ (z = w_{1}x_{1} + w_{2}x_{2} + \\cdots + w_{n}x_{n} = x^{T}w), $$ \n",
    "\n",
    "* luego aplica una **función de paso** a esa suma y genera el resultado: \n",
    "$$ h_{w}(x) = step(z), $$\n",
    "\n",
    "donde $z = x^{T}w$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c9c684",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/figure_10_4.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8f166",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La función escalonada más común utilizada en los perceptrones es la **función escalonada de Heaviside** (consulte la ecuación 10-1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44f6a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A veces se usa la **función signo** en su lugar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5487b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Equation 10-1. Funciones de paso comunes utilizadas en perceptrones (suponiendo umbral = 0)\n",
    "\n",
    "\n",
    "$$ \\text{heaviside}(z) = \\begin{cases} 0 & \\text{si}\\ z < 0 \\\\ 1 & \\text{si}\\ z \\geq 0 \\end{cases} $$\n",
    "\n",
    "$$ sgn(z) = \\begin{cases} -1 & \\text{si}\\ z < 0 \\\\ 0 & \\text{si}\\ z = 0 \\\\ 1 & \\text{si}\\ z > 0 \\end{cases} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b528671",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Se puede utilizar una única TLU para **la clasificación binaria lineal simple**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca05f38c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Calcula una combinación lineal de las entradas y, \n",
    "* si el resultado supera un umbral, genera la clase positiva. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15574db2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De lo contrario, genera la clase negativa   \n",
    "* (al igual que una regresión logística o un clasificador SVM lineal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f316365",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Podría, por ejemplo, usar una sola TLU para clasificar las flores de iris en función de la longitud y el ancho de los pétalos (también agregando una función de sesgo adicional $x_{0} = 1$, tal como lo hicimos en capítulos anteriores)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b7603",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Entrenar una TLU en este caso significa encontrar los valores correctos para $w_{0}, w_{1}$ y $w_{2}$ (el algoritmo de entrenamiento se analiza en breve)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a6fbb9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Un Perceptron se compone simplemente de una sola capa de TLU, con cada TLU conectada a todas las entradas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62432e4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando todas las neuronas de una capa están conectadas a cada neurona de la capa anterior (es decir, sus neuronas de entrada), la capa se denomina capa totalmente conectada o **capa densa**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb88f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las entradas del Perceptron se alimentan a neuronas de paso especiales llamadas neuronas de entrada: emiten cualquier entrada que reciban."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e72611",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Todas las neuronas de entrada forman la capa de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ecdd67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Además, generalmente se agrega una función de sesgo adicional $(x_{0} = 1)$:   \n",
    "* generalmente se representa usando un tipo especial de neurona llamada neurona de sesgo, que genera 1 todo el tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd70642",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En la figura 10-5 se representa un perceptrón con dos entradas y tres salidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed156dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/figure_10_5.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b97e5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Este Perceptron puede clasificar instancias simultáneamente en tres clases binarias diferentes, \n",
    "* lo que lo convierte en un **clasificador de salida múltiple**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66075f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gracias a la magia del álgebra lineal, la Ecuación 10-2 hace posible calcular eficientemente las salidas de una capa de neuronas artificiales para varias instancias a la vez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c5e31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ecuación 10-2. Cálculo de las salidas de una capa completamente conectada\n",
    "\n",
    "$$ h_{w,b}(X) = \\phi(XW+ b)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9359dfb4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En esta ecuación:\n",
    "\n",
    "* Como siempre, $X$ representa la matriz de características de entrada. Tiene una fila por instancia y una columna por atributo.\n",
    "\n",
    "* La matriz de pesos $W$ contiene todos los pesos de conexión excepto los de la neurona de polarización. Tiene una fila por neurona de entrada y una columna por neurona artificial en la capa.\n",
    "\n",
    "* El vector de sesgo $b$ contiene todos los pesos de conexión entre la neurona de sesgo y las neuronas artificiales. Tiene un término de sesgo por neurona artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afaada",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* La función $\\phi$ se llama **función de activación**: cuando las neuronas artificiales son TLU, es una función escalonada (pero discutiremos otras funciones de activación en breve)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b6d58",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Entonces, ¿cómo se forma un Perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe73d60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El algoritmo de entrenamiento de Perceptron propuesto por Rosenblatt se inspiró en gran medida en la regla de Hebb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46c2176",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En su libro de 1949 La Organización del Comportamiento (Wiley), Donald Hebb sugirió que cuando una neurona biológica desencadena a menudo otra neurona, la conexión entre estas dos neuronas se vuelve más fuerte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15dd59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Siegrid Löwel luego resumió la idea de Hebb en la frase pegadiza, \"Células que disparan juntas, se conectan juntas\"; es decir, el peso de la conexión entre dos neuronas tiende a aumentar cuando disparan simultáneamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7fda75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esta regla más tarde se conoció como la regla de Hebb (o aprendizaje hebbiano)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4a7f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Los perceptrones se entrenan mediante una variante de esta regla que tiene en cuenta el error que comete la red cuando realiza una predicción;   \n",
    "* la regla de aprendizaje de Perceptron refuerza las conexiones que ayudan a reducir el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2998b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Más específicamente,   \n",
    "* el Perceptron recibe una instancia de entrenamiento a la vez, y   \n",
    "* para cada instancia hace sus predicciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f5c16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por cada neurona de salida que produjo una predicción incorrecta, refuerza los pesos de conexión de las entradas que habrían contribuido a la predicción correcta. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9159370",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La regla se muestra en la Ecuación 10-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2295a445",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ecuación 10-3. Regla de aprendizaje de perceptrón (actualización de peso)\n",
    "\n",
    "$$ w_{i,j}^{(\\text{next step})} = w_{i,j} + \\eta(y_{j} - \\hat{y}_{j})x_{i} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4797c69",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En esta ecuación:\n",
    "\n",
    "* $w_{i,j}$ es el peso de conexión entre la $i$ ésima neurona de entrada y la $j$ ésima neurona de salida.\n",
    "* $x_{i}$ es el valor de entrada $i$ de la instancia de entrenamiento actual.\n",
    "* $\\hat{y}_{j}$ es la salida de la neurona de salida $j$ para la instancia de entrenamiento actual.\n",
    "* $y_{j}$ es la salida objetivo de la neurona de salida $j$ para la instancia de entrenamiento actual.\n",
    "* $\\eta$ es la tasa de aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c36ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El límite de decisión de cada neurona de salida es lineal, por lo que los perceptrones son incapaces de aprender patrones complejos (al igual que los clasificadores de regresión logística)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343e1fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, si las instancias de entrenamiento **son linealmente separables**, Rosenblatt demostró que este algoritmo convergería en una solución."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4a8ea0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto se llama el **teorema de convergencia del perceptrón**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f2f238",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-Learn proporciona una clase `Perceptron` que implementa una red de una sola TLU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ae0bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Se puede usar más o menos como cabría esperar, por ejemplo, en el conjunto de datos del iris (presentado en el Capítulo 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4aed47b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int64) # Iris setosa?\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)\n",
    "y_pred = per_clf.predict([[2, 0.5]]) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8225006",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Graficación de las clases y del perceptrón clasificador\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84100ff3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots()     # creación de la figura y el sistema de ejes\n",
    "ax.set(title = 'Detector de setosa con Perceptrón',\\\n",
    "       xlabel = 'longitud pétalo', ylabel = 'ancho de pétalo' )  # darle título a la figura \n",
    "# definir las longitudes del rectángulo de visualización\n",
    "e,f,g,j = np.min(X[:,0])-0.4, np.max(X[:,0])+0.4, np.min(X[:,1])-0.4, np.max(X[:,1])+0.4 \n",
    "ax.axis([e,f,g,j]) \n",
    "\n",
    "#Gráfica de la clase positiva\n",
    "ax.plot(X[:,0][y==1], X[:,1][y==1], 'r.', label = 'clase positiva: Setosa')\n",
    "\n",
    "#Gráfica de la clase negativa\n",
    "ax.plot(X[:,0][y==0], X[:,1][y==0], 'b.', label = 'Clase negativa:No setosa')\n",
    "\n",
    "\n",
    "w0,w1,w2 = per_clf.intercept_[0], per_clf.coef_[0][0], per_clf.coef_[0][1]\n",
    "\n",
    "m, b = -w1/w2, -w0/w2\n",
    "\n",
    "x0 = [e,f]\n",
    "\n",
    "threshold = [e*m + b, f*m+b]\n",
    "\n",
    "ax.plot(x0, threshold, 'k--', label = 'perceptrón')\n",
    "\n",
    "\n",
    "# ponerle convenciones a las clases\n",
    "ax.legend()\n",
    "\n",
    "ax.grid(alpha = 0.4)\n",
    "plt.savefig('clasificacion_con_perceptron.png')\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deb6f8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es posible que haya notado que el algoritmo de aprendizaje de Perceptron se parece mucho al descenso de gradiente estocástico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3312376",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "De hecho, la clase Perceptron de Scikit-Learn es equivalente a usar un SGDClassifier con los siguientes hiperparámetros: `loss=\"perceptron\", learning_rate=\"constant\", eta0=1` (la tasa de aprendizaje) y `penalty=None` (no regularización)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee442445",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tenga en cuenta que, a diferencia de los clasificadores de regresión logística, los perceptrones no generan una **probabilidad de clase**;   \n",
    "* más bien, hacen predicciones basadas en un **umbral** estricto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82954680",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esta es una de las razones para preferir la regresión logística a los perceptrones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b207ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# El problema de clasificación OR Exclusive (XOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9ddb1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "En su monografía Perceptrons de 1969, Marvin Minsky y Seymour Papert destacaron una serie de debilidades graves de los perceptrones, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ec0c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "en particular, el hecho de que son incapaces de resolver algunos problemas triviales (por ejemplo, el problema de clasificación OR Exclusive (XOR);   \n",
    "\n",
    "* consulte el lado izquierdo de la Figura 10-6)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a091736",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/figure_10_6.jpg?raw=true'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b60b690",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto es cierto para cualquier otro modelo de clasificación lineal (como los clasificadores de regresión logística), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650bd8d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "pero los investigadores esperaban mucho más de los perceptrones, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721f7d7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "y algunos estaban tan decepcionados que abandonaron las redes neuronales por completo en favor de problemas de nivel superior como lógica, resolución de problemas y búsqueda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d2fd54",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solución al problema del Perceptron en cuanto a la clasificación XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f765d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Resulta que algunas de las limitaciones de los perceptrones pueden eliminarse apilando varios perceptrones. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362ac11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La RNA resultante se denomina **perceptrón multicapa** (MLP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdd32ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Un MLP puede resolver el problema XOR, como puede verificar calculando la salida del MLP representado en el lado derecho de la Figura 10-6:   \n",
    "* con entradas $(0, 0)$ o $(1, 1)$, la red genera 0, y   \n",
    "* con entradas $(0, 1)$ o $(1, 0)$ genera $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2596f42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Todas las conexiones tienen un peso igual a 1, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b420cf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "excepto las cuatro conexiones donde se muestra el peso. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f8a5de",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "¡Intente verificar que esta red realmente resuelve el problema XOR!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de9b9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Verificación de que la red de Geron resuelve el problema XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a7dc1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## El perceptrón multicapa y la retropropagación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c9745",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Un MLP se compone de una capa de entrada (de paso), una o más capas de TLU, llamadas capas ocultas, y una capa final de TLU llamada capa de salida (consulte la Figura 10-7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2949dc8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Las capas cercanas a la capa de entrada generalmente se denominan capas inferiores, y las cercanas a las salidas generalmente se denominan capas superiores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78dc9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/figure_10_7.jpg?raw=true'> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4113d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cada capa, excepto la capa de salida, incluye una neurona de polarización y está completamente conectada a la siguiente capa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd05ff2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee6d91",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La señal fluye solo en una dirección (de las entradas a las salidas), por lo que esta arquitectura es un ejemplo de una red neuronal feedforward (FNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd44f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando una ANN contiene una pila profunda de capas ocultas, se denomina red neuronal profunda (DNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a4a22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El campo del aprendizaje profundo estudia las DNN y, en general, los modelos que contienen pilas profundas de cálculos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63933721",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aun así, mucha gente habla de Deep Learning cuando se trata de redes neuronales (incluso superficiales)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898bdeb2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Durante muchos años, los investigadores lucharon por encontrar una manera de entrenar a los MLP, sin éxito."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24dfead",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pero en 1986, David Rumelhart, Geoffrey Hinton y Ronald Williams publicaron un artículo innovador que introdujo la\n",
    "algoritmo de entrenamiento de retropropagación, que todavía se usa en la actualidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d83ff3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En resumen, es Gradient Descent (presentado en el Capítulo 4) que utiliza una técnica eficiente para calcular los gradientes automáticamente: en solo dos pasadas a través de la red (una hacia adelante y otra hacia atrás), el algoritmo de retropropagación puede calcular el gradiente de la red. error con respecto a cada parámetro del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05bb67e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En otras palabras, puede averiguar cómo se debe ajustar cada peso de conexión y cada término de sesgo para reducir el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6213116",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una vez que tiene estos gradientes, simplemente realiza un paso de descenso de gradiente regular y todo el proceso se repite hasta que la red converge a la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77162cbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c073f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El cálculo automático de gradientes se denomina diferenciación automática o autodiff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17210b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Existen varias técnicas de autodiferenciación, con diferentes pros y contras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e271af4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "El que usa la retropropagación se llama diferenciación automática en modo inverso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61475a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es rápido y preciso, y es adecuado cuando la función para diferenciar tiene muchas variables (p. ej., pesos de conexión) y pocas salidas (p. ej., una pérdida)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdcd823",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si desea obtener más información sobre autodiff, consulte el Apéndice D."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3397ede",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Analicemos este algoritmo con un poco más de detalle: maneja un mini lote a la vez (por ejemplo, que contiene 32 instancias cada uno) y pasa por el conjunto de entrenamiento completo varias veces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b2650",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cada paso se llama una época."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f381843b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cada minilote se pasa a la capa de entrada de la red, que lo envía a la primera capa oculta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c7e9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The algorithm then computes the output of all the neurons in this layer (for every instance in the mini-batch). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144103c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The result is passed on to the next layer, its output is computed and passed to the next layer, and so on until we get the output of the last layer, the output layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82d32b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is the forward pass: it is exactly like making predictions, except all intermediate results are preserved since they are needed for the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed898e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, the algorithm measures the network’s output error (i.e., it uses a loss function that compares the desired output and the actual output of the network, and returns some measure of the error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d18eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then it computes how much each output connection contributed to the error. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4289dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is done analytically by applying the chain rule (perhaps the most fundamental rule in calculus), which makes this\n",
    "step fast and precise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee2bda",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The algorithm then measures how much of these error contributions came from each connection in the layer below, again\n",
    "using the chain rule, working backward until the algorithm reaches the input layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66501936",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As explained earlier, this reverse pass efficiently measures the error gradient across all the connection weights in the\n",
    "network by propagating the error gradient backward through the network (hence the name of the algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0acd277",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, the algorithm performs a Gradient Descent step to tweak all the connection weights in the network, using the error gradients it just computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1a8ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This algorithm is so important that it’s worth summarizing it again: for each training instance, the backpropagation algorithm first makes a prediction (forward pass) and measures the error, then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally tweaks the connection weights to reduce the error (Gradient Descent step)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf080353",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ADVERTENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fc7eb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Es importante inicializar aleatoriamente todos los pesos de conexión de las capas ocultas, de lo contrario, el entrenamiento fallará. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfcedcc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, if you initialize all weights and biases to zero, then all neurons in a given layer will be perfectly identical, and thus backpropagation will affect them in exactly the same way, so they will remain identical. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde55bea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In other words, despite having hundreds of neurons per layer, your model will act as if it had only one neuron per layer: it won’t be too smart. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922199a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If instead you randomly initialize the weights, you break the symmetry and allow backpropagation to train a diverse team of neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1818dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In order for this algorithm to work properly, its authors made a key change to the MLP’s architecture: they replaced the step function with the logistic (sigmoid) function, $\\sigma(z) = 1 / (1 + exp(–z))$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02051d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This was essential because the step function contains only flat segments, so there is no gradient to work with (Gradient Descent cannot move on a flat surface), while the logistic function has a well-defined nonzero derivative everywhere, allowing Gradient Descent to make some progress at every step. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc164e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In fact, the backpropagation algorithm works well with many other activation functions, not just the logistic function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba667b68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here are two other popular choices: The hyperbolic tangent function: $\\tanh(z) = 2\\sigma(2z) – 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fc5fe9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Just like the logistic function, this activation function is S-shaped, continuous, and differentiable, but its output value ranges from –1 to 1 (instead of 0 to 1 in the case of the logistic function). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b714a65",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That range tends to make each layer’s output more or less centered around 0 at the beginning of training, which often helps speed up convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9868c29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Rectified Linear Unit function:   \n",
    "\n",
    "$$ ReLU(z) = max(0, z) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5d07c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The ReLU function is continuous but unfortunately not differentiable at $z = 0$ (the slope changes abruptly, which can make Gradient Descent bounce around), and its derivative is 0 for $z < 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ce7e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In practice, however, it works very well and has the advantage of being fast to compute, so it has become the default. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7112abbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Most importantly, the fact that it does not have a maximum output value helps reduce some issues during Gradient Descent (we will come back to this in Chapter 11)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d012501",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These popular activation functions and their derivatives are represented in Figure 10-8. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d768919",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But wait! Why do we need activation functions in the first place? Well, if you chain several linear transformations, all you get is a linear transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ccf30f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, if $f(x) = 2x + 3$ and $g(x) = 5x – 1$, then chaining these two linear functions gives you another linear function:\n",
    "$f(g(x)) = 2(5x – 1) + 3 = 10x + 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a41c26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So if you don’t have some nonlinearity between layers, then even a deep stack of layers is equivalent to a single layer, and you can’t solve very complex problems with that. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fff8b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Conversely, a large enough DNN with nonlinear activations can theoretically approximate any continuous function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac0d0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/figure_10_8.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3c530",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK! You know where neural nets came from, what their architecture is, and how to compute their outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b7f6b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You’ve also learned about the backpropagation algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6fe221",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But what exactly can you do with them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c3462",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536166c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, MLPs can be used for regression tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e0f79",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want to predict a single value (e.g., the price of a house, given many of its features), then you just need a single output neuron: its output is the predicted value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834ab9d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For multivariate regression (i.e., to predict multiple values at once), you need one output neuron per output dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10586824",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, to locate the center of an object in an image, you need to predict 2D coordinates, so you need two output neurons. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84ff6d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you also want to place a bounding box around the object, then you need two more numbers: the width and the height of the\n",
    "object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d18ac97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, you end up with four output neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485d6d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In general, when building an MLP for regression, you do not want to use any activation function for the output neurons, so they are free to output any range of values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d14ddd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want to guarantee that the output will always be positive, then you can use the ReLU activation function in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada18b2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternatively, you can use the softplus activation function, which is a smooth variant of ReLU: $softplus(z) = log(1 + exp(z))$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed1573",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is close to 0 when z is negative, and close to z when z is positive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959d358",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, if you want to guarantee that the predictions will fall within a given range of values, then you can use the logistic function or the hyperbolic tangent, and then scale the labels to the appropriate range: 0 to 1 for the logistic function and –1 to 1 for the hyperbolic tangent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543dbdad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The loss function to use during training is typically the mean squared error, but if you have a lot of outliers in the training set, you may prefer to use the mean absolute error instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3b0d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Alternatively, you can use the Huber loss, which is a combination of both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9630ff3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sugerencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd3fa76",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Huber loss is quadratic when the error is smaller than a threshold $\\delta$ (typically 1) but linear when the error is larger than $\\delta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f531ad5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The linear part makes it less sensitive to outliers than the mean squared error, and the quadratic part allows it to converge faster and be more precise than the mean absolute error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd5f2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Table 10-1 summarizes the typical architecture of a regression MLP  \n",
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/table_10_1.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31fbdde",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfff821",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "MLPs can also be used for classification tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b90453",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For a binary classification problem, you just need a single output neuron using the logistic activation function: the output will be a number between 0 and 1, which you can interpret as the estimated probability of the positive class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcfd72f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The estimated probability of the negative class is equal to one minus that number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1297b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "MLPs can also easily handle multilabel binary classification tasks (see Chapter 3). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e660c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, you could have an email classification system that predicts whether each incoming email is ham or spam, and simultaneously predicts whether it is an urgent or nonurgent email. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce23c06",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In this case, you would need two output neurons, both using the logistic activation function: the first would output the probability that the email is spam, and the second would output the probability that it is urgent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb14f0c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More generally, you would dedicate one output neuron for each positive class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac641f3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that the output probabilities do not necessarily add up to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c8331",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This lets the model output any combination of labels: you can have nonurgent ham, urgent ham, nonurgent spam, and perhaps even urgent spam (although that would probably be an error)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e8e2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If each instance can belong only to a single class, out of three or more possible classes (e.g., classes 0 through 9 for digit image classification), then you need to have one output neuron per class, and you should use the softmax activation function for the whole output layer (see Figure 10-9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb99c2f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The softmax function (introduced in Chapter 4) will ensure that all the estimated probabilities are between 0 and 1 and that they add up to 1 (which is required if the classes are exclusive). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d622ad3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is called multiclass classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f835c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/figure_10_9.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4395c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Regarding the loss function, since we are predicting probability distributions, the cross-entropy loss (also called the log loss, see Chapter 4) is generally a good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea68b28",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Table 10-2 summarizes the typical architecture of a classification MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be0b0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = 'https://github.com/marco-canas/didactica_ciencia_datos/blob/main/referentes/geron/part_2/c_10/table_10_2.jpg?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697654d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594a758",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before we go on, I recommend you go through exercise 1 at the end of this chapter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b8f5e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You will play with various neural network architectures and visualize their outputs using the TensorFlow Playground. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13611b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This will be very useful to better understand MLPs, including the effects of all the hyperparameters (number of layers and neurons, activation functions, and more)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a5aa7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now you have all the concepts you need to start implementing MLPs with Keras!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165997ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing MLPs with Keras Página 379 de Geron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff1214",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Keras is a high-level Deep Learning API that allows you to easily build, train, evaluate, and execute all sorts of neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ffa70a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Its documentation (or specification) is available at https://keras.io/. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ca3c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The reference implementation, also called Keras, was developed by François Chollet as part of a research project and was released as an open source project in March 2015. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439aa92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It quickly gained popularity, owing to its ease of use, flexibility, and beautiful design. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a219741a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To perform the heavy computations required by neural networks, this reference implementation relies on a computation backend. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b12a58",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "At present, you can choose from three popular open source Deep Learning libraries: TensorFlow, Microsoft Cognitive Toolkit\n",
    "(CNTK), and Theano. Therefore, to avoid any confusion, we will refer to\n",
    "this reference implementation as multibackend Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a2fe9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since late 2016, other implementations have been released. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8d842c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can now run Keras on Apache MXNet, Apple’s Core ML, JavaScript or TypeScript (to run Keras code in a web browser), and PlaidML (which can run on all sorts of GPU devices, not just Nvidia). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8e6e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Moreover, TensorFlow itself now comes bundled with its own Keras implementation, tf.keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a10c57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It only supports TensorFlow as the backend, but it has the advantage of offering some very useful extra features (see Figure 10-10): for example, it supports TensorFlow’s Data API, which makes it easy to load and preprocess data efficiently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa3491",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For this reason, we will use tf.keras in this book. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2afebd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, in this chapter we will not use any of the TensorFlow-specific features, so the code should run fine on other Keras implementations as well (at least in Python), with only minor modifications, such as changing the imports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60e65e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src = ''>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73aef44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aad2d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6acf7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9895079",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "698a2048",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Referentes  \n",
    "\n",
    "* La clase Perceptron de sklearn: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e1c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "rise": {
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
